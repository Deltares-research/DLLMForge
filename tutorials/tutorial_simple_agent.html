<!DOCTYPE html>

<html lang="en" data-content_root="../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Building a Simple Agent with DLLMForge &#8212; dllmforge  documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=5ecbeea2" />
    <link rel="stylesheet" type="text/css" href="../_static/basic.css?v=686e5160" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css?v=27fed22d" />
    <script src="../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Tutorial: Advanced Water Management Agent" href="tutorial_advanced_agent.html" />
    <link rel="prev" title="Open Source RAG Pipeline Tutorial" href="RAG_tutorial.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="building-a-simple-agent-with-dllmforge">
<h1>Building a Simple Agent with DLLMForge<a class="headerlink" href="#building-a-simple-agent-with-dllmforge" title="Link to this heading">¶</a></h1>
<p>This tutorial demonstrates how to build a simple tool-using agent using DLLMForge. You will learn how to configure different LLM providers (Azure OpenAI, OpenAI, Mistral, or Deltares-hosted models), create custom tools, and build an agent that can perform calculations and answer questions about pizza prices.</p>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Link to this heading">¶</a></h2>
<p>The simple agent tutorial consists of several key components:</p>
<ol class="arabic simple">
<li><p><strong>Environment Setup</strong>: Configure API keys and credentials for different LLM providers</p></li>
<li><p><strong>Tool Creation</strong>: Define custom tools using the DLLMForge <code class="docutils literal notranslate"><span class="pre">&#64;tool</span></code> decorator</p></li>
<li><p><strong>Agent Initialization</strong>: Create a SimpleAgent with your chosen LLM provider</p></li>
<li><p><strong>Tool Integration</strong>: Add tools to the agent and compile the agent</p></li>
<li><p><strong>Query Processing</strong>: Test the agent with various queries and observe tool routing</p></li>
<li><p><strong>Provider Switching</strong>: Change between different LLM providers without code changes</p></li>
</ol>
<section id="prerequisites">
<h3>Prerequisites<a class="headerlink" href="#prerequisites" title="Link to this heading">¶</a></h3>
<ol class="arabic simple">
<li><p>Python environment with the project requirements installed</p></li>
<li><p>A <code class="docutils literal notranslate"><span class="pre">.env</span></code> file in your project root with provider credentials (see below)</p></li>
<li><p>Optional: IPython/Jupyter if you want to display the LangGraph diagram</p></li>
</ol>
</section>
</section>
<section id="step-by-step-implementation">
<h2>Step-by-Step Implementation<a class="headerlink" href="#step-by-step-implementation" title="Link to this heading">¶</a></h2>
<section id="environment-setup">
<h3>1. Environment Setup<a class="headerlink" href="#environment-setup" title="Link to this heading">¶</a></h3>
<p>Create or update your <code class="docutils literal notranslate"><span class="pre">.env</span></code> with the variables for the providers you plan to use.</p>
<p>Azure OpenAI (default in DLLMForge examples):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">AZURE_OPENAI_ENDPOINT</span><span class="o">=</span>https://your-azure-endpoint
<span class="nv">AZURE_OPENAI_API_KEY</span><span class="o">=</span>your_azure_openai_api_key
<span class="nv">AZURE_OPENAI_DEPLOYMENT_NAME</span><span class="o">=</span>your_deployment_name
<span class="nv">AZURE_OPENAI_API_VERSION</span><span class="o">=</span><span class="m">2024</span>-12-01-preview
</pre></div>
</div>
<p>OpenAI:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">OPENAI_API_KEY</span><span class="o">=</span>your_openai_api_key
<span class="nv">OPENAI_MODEL_NAME</span><span class="o">=</span>gpt-4.1<span class="w">  </span><span class="c1"># or gpt-4o, etc.</span>
</pre></div>
</div>
<p>Mistral:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">MISTRAL_API_KEY</span><span class="o">=</span>your_mistral_api_key
<span class="nv">MISTRAL_MODEL_NAME</span><span class="o">=</span>mistral-large-latest
</pre></div>
</div>
<p>Deltares-hosted (no API key; requires Deltares network/VPN):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># No keys required; you will specify base_url and model at runtime</span>
</pre></div>
</div>
</section>
<section id="import-required-modules">
<h3>2. Import Required Modules<a class="headerlink" href="#import-required-modules" title="Link to this heading">¶</a></h3>
<p>Start by importing all necessary components:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">dllmforge.agent_core</span><span class="w"> </span><span class="kn">import</span> <span class="n">SimpleAgent</span><span class="p">,</span> <span class="n">tool</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">dllmforge.langchain_api</span><span class="w"> </span><span class="kn">import</span> <span class="n">LangchainAPI</span>

<span class="c1"># Basic math tools</span>
<span class="nd">@tool</span>
<span class="k">def</span><span class="w"> </span><span class="nf">add</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Add two numbers together.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span>

<span class="nd">@tool</span>
<span class="k">def</span><span class="w"> </span><span class="nf">subtract</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Subtract two numbers from each other.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">a</span> <span class="o">-</span> <span class="n">b</span>

<span class="nd">@tool</span>
<span class="k">def</span><span class="w"> </span><span class="nf">multiply</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Multiply two numbers.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">a</span> <span class="o">*</span> <span class="n">b</span>

<span class="nd">@tool</span>
<span class="k">def</span><span class="w"> </span><span class="nf">divide</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Divide two numbers.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">a</span> <span class="o">/</span> <span class="n">b</span>

<span class="c1"># Pizza pricing tool</span>
<span class="nd">@tool</span>
<span class="k">def</span><span class="w"> </span><span class="nf">get_pizza_price</span><span class="p">(</span><span class="n">pizza_type</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get the price of a pizza type.&quot;&quot;&quot;</span>
    <span class="n">prices</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;margherita&quot;</span><span class="p">:</span> <span class="mf">12.99</span><span class="p">,</span>
        <span class="s2">&quot;pepperoni&quot;</span><span class="p">:</span> <span class="mf">15.99</span><span class="p">,</span>
        <span class="s2">&quot;vegetarian&quot;</span><span class="p">:</span> <span class="mf">14.99</span><span class="p">,</span>
        <span class="s2">&quot;supreme&quot;</span><span class="p">:</span> <span class="mf">17.99</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="n">prices</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">pizza_type</span><span class="o">.</span><span class="n">lower</span><span class="p">(),</span> <span class="mf">10.99</span><span class="p">)</span>

<span class="c1"># LLM-powered summary tool</span>
<span class="nd">@tool</span>
<span class="k">def</span><span class="w"> </span><span class="nf">make_summary</span><span class="p">(</span><span class="n">question</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">result</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Use the configured LLM to create a concise, conversational summary.&quot;&quot;&quot;</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">dllmforge.langchain_api</span><span class="w"> </span><span class="kn">import</span> <span class="n">LangchainAPI</span>
    <span class="n">llm_api</span> <span class="o">=</span> <span class="n">LangchainAPI</span><span class="p">()</span>  <span class="c1"># honors your .env + default provider</span>
    <span class="n">messages</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">(</span><span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="s2">&quot;You are a helpful assistant. Create a concise, friendly summary of the provided result in the context of the question. Mention all of the tools that you used&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">&quot;human&quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Question:</span><span class="se">\n</span><span class="si">{</span><span class="n">question</span><span class="si">}</span><span class="se">\n\n</span><span class="s2">Result:</span><span class="se">\n</span><span class="si">{</span><span class="n">result</span><span class="si">}</span><span class="se">\n\n</span><span class="s2">Please return a brief, conversational summary (1-3 sentences).&quot;</span><span class="p">)</span>
    <span class="p">]</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">llm_api</span><span class="o">.</span><span class="n">llm</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="n">messages</span><span class="p">)</span>
    <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">response</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">response</span><span class="p">))</span>

<span class="n">agent</span> <span class="o">=</span> <span class="n">SimpleAgent</span><span class="p">(</span>
    <span class="s2">&quot;You are a helpful assistant that can do math and tell you about pizza prices. Only use the tools, do not try to do maths in your head.&quot;</span><span class="p">,</span>
    <span class="n">model_provider</span><span class="o">=</span><span class="s2">&quot;azure-openai&quot;</span><span class="p">,</span>
    <span class="n">temperature</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">agent</span><span class="o">.</span><span class="n">add_tool</span><span class="p">(</span><span class="n">make_summary</span><span class="p">)</span>
<span class="n">agent</span><span class="o">.</span><span class="n">add_tool</span><span class="p">(</span><span class="n">divide</span><span class="p">)</span>
<span class="n">agent</span><span class="o">.</span><span class="n">add_tool</span><span class="p">(</span><span class="n">multiply</span><span class="p">)</span>
<span class="n">agent</span><span class="o">.</span><span class="n">add_tool</span><span class="p">(</span><span class="n">add</span><span class="p">)</span>
<span class="n">agent</span><span class="o">.</span><span class="n">add_tool</span><span class="p">(</span><span class="n">subtract</span><span class="p">)</span>
<span class="n">agent</span><span class="o">.</span><span class="n">add_tool</span><span class="p">(</span><span class="n">get_pizza_price</span><span class="p">)</span>
<span class="n">agent</span><span class="o">.</span><span class="n">compile</span><span class="p">()</span>
</pre></div>
</div>
<p>Run it:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="n">pizza_course_tutorial_ultra_simple</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
<section id="testing-the-agent">
<h4>Testing the agent<a class="headerlink" href="#testing-the-agent" title="Link to this heading">¶</a></h4>
<p>Once your agent is compiled, you can test it with various queries. Here’s an example that demonstrates the agent’s ability to handle complex calculations involving pizza prices and fractions:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">agent</span><span class="o">.</span><span class="n">process_query</span><span class="p">(</span><span class="s2">&quot;If I had half a pepperoni pizza and 1/4 of a margherita pizza and I paid for both pizzas. How much should I Tikkie my friend?&quot;</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>This query will:
1. Calculate the price of a pepperoni pizza (15.99)
2. Calculate the price of a margherita pizza (12.99)
3. Determine half of the pepperoni price (7.995)
4. Determine 1/4 of the margherita price (3.2475)
5. Calculate the total amount your friend owes (11.2425)
6. Generate a friendly summary using the LLM</p>
<p>The agent uses its maths and pizza tools for calculations and the summary tool to provide a conversational response.</p>
</section>
</section>
<section id="switching-providers">
<h3>Switching providers<a class="headerlink" href="#switching-providers" title="Link to this heading">¶</a></h3>
<p>To change providers, keep your code the same and switch the agent argument and/or your <code class="docutils literal notranslate"><span class="pre">.env</span></code>.</p>
<p>Azure OpenAI (default):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">agent</span> <span class="o">=</span> <span class="n">SimpleAgent</span><span class="p">(</span><span class="n">system_message</span><span class="p">,</span> <span class="n">model_provider</span><span class="o">=</span><span class="s2">&quot;azure-openai&quot;</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</pre></div>
</div>
<p>OpenAI:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">agent</span> <span class="o">=</span> <span class="n">SimpleAgent</span><span class="p">(</span><span class="n">system_message</span><span class="p">,</span> <span class="n">model_provider</span><span class="o">=</span><span class="s2">&quot;openai&quot;</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="c1"># Requires OPENAI_API_KEY and OPENAI_MODEL_NAME</span>
</pre></div>
</div>
<p>Mistral:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">agent</span> <span class="o">=</span> <span class="n">SimpleAgent</span><span class="p">(</span><span class="n">system_message</span><span class="p">,</span> <span class="n">model_provider</span><span class="o">=</span><span class="s2">&quot;mistral&quot;</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="c1"># Requires MISTRAL_API_KEY and MISTRAL_MODEL_NAME</span>
</pre></div>
</div>
</section>
<section id="using-alternative-integration-layers">
<h3>Using alternative integration layers<a class="headerlink" href="#using-alternative-integration-layers" title="Link to this heading">¶</a></h3>
<p>You can also work directly with the integration classes if you prefer those patterns.</p>
<p>LlamaIndex API:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">dllmforge.llamaindex_api</span><span class="w"> </span><span class="kn">import</span> <span class="n">LlamaIndexAPI</span>
<span class="n">api_llama_openai</span> <span class="o">=</span> <span class="n">LlamaIndexAPI</span><span class="p">(</span><span class="n">model_provider</span><span class="o">=</span><span class="s2">&quot;openai&quot;</span><span class="p">)</span>
<span class="n">api_llama_mistral</span> <span class="o">=</span> <span class="n">LlamaIndexAPI</span><span class="p">(</span><span class="n">model_provider</span><span class="o">=</span><span class="s2">&quot;mistral&quot;</span><span class="p">)</span>
<span class="n">api_llama_azure</span>   <span class="o">=</span> <span class="n">LlamaIndexAPI</span><span class="p">(</span><span class="n">model_provider</span><span class="o">=</span><span class="s2">&quot;azure-openai&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>LangChain API:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">dllmforge.langchain_api</span><span class="w"> </span><span class="kn">import</span> <span class="n">LangchainAPI</span>
<span class="n">api_lc_openai</span> <span class="o">=</span> <span class="n">LangchainAPI</span><span class="p">(</span><span class="n">model_provider</span><span class="o">=</span><span class="s2">&quot;openai&quot;</span><span class="p">)</span>
<span class="n">api_lc_mistral</span> <span class="o">=</span> <span class="n">LangchainAPI</span><span class="p">(</span><span class="n">model_provider</span><span class="o">=</span><span class="s2">&quot;mistral&quot;</span><span class="p">)</span>
<span class="n">api_lc_azure</span>   <span class="o">=</span> <span class="n">LangchainAPI</span><span class="p">(</span><span class="n">model_provider</span><span class="o">=</span><span class="s2">&quot;azure-openai&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Deltares-hosted models:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">dllmforge.LLMs.Deltares_LLMs</span><span class="w"> </span><span class="kn">import</span> <span class="n">DeltaresOllamaLLM</span>
<span class="n">base_url</span> <span class="o">=</span> <span class="s2">&quot;https://chat-api.directory.intra&quot;</span>
<span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;llama3.1:70b&quot;</span>
<span class="n">llm</span> <span class="o">=</span> <span class="n">DeltaresOllamaLLM</span><span class="p">(</span><span class="n">base_url</span><span class="o">=</span><span class="n">base_url</span><span class="p">,</span> <span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="asking-questions-integration-classes">
<h3>Asking questions (integration classes)<a class="headerlink" href="#asking-questions-integration-classes" title="Link to this heading">¶</a></h3>
<p>All integration classes accept message lists and return responses from the model.</p>
<p>Messages example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">messages</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;You are a helpful assistant.&quot;</span><span class="p">},</span>
    <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;What is the capital of France?&quot;</span><span class="p">},</span>
<span class="p">]</span>
</pre></div>
</div>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># LlamaIndex</span>
<span class="n">response_llama</span> <span class="o">=</span> <span class="n">api_llama_openai</span><span class="o">.</span><span class="n">chat_completions</span><span class="p">(</span><span class="n">messages</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;LlamaIndex OpenAI Response:&quot;</span><span class="p">,</span> <span class="n">response_llama</span><span class="p">)</span>

<span class="c1"># LangChain</span>
<span class="n">response_lc</span> <span class="o">=</span> <span class="n">api_lc_openai</span><span class="o">.</span><span class="n">chat_completions</span><span class="p">(</span><span class="n">messages</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;LangChain OpenAI Response:&quot;</span><span class="p">,</span> <span class="n">response_lc</span><span class="p">)</span>

<span class="c1"># Deltares-hosted</span>
<span class="n">response_deltares</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">chat_completions</span><span class="p">(</span><span class="n">messages</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Deltares Model Response:&quot;</span><span class="p">,</span> <span class="n">response_deltares</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="notes-on-temperature-and-max-tokens-deltares-hosted">
<h3>Notes on temperature and max tokens (Deltares-hosted)<a class="headerlink" href="#notes-on-temperature-and-max-tokens-deltares-hosted" title="Link to this heading">¶</a></h3>
<p>For Deltares-hosted models you may pass parameters like <code class="docutils literal notranslate"><span class="pre">temperature</span></code> and <code class="docutils literal notranslate"><span class="pre">max_tokens</span></code> to control creativity and output length. A lower temperature (e.g., 0.0–0.3) yields more deterministic outputs; higher values produce more diverse outputs. Use <code class="docutils literal notranslate"><span class="pre">max_tokens</span></code> to bound response size for summaries and UI constraints.</p>
<p>Tip: To disable extended “thinking” modes where supported, pass a <code class="docutils literal notranslate"><span class="pre">/no_think</span></code> flag in the user content convention used by your deployment.</p>
</section>
<section id="next-steps">
<h3>Next steps<a class="headerlink" href="#next-steps" title="Link to this heading">¶</a></h3>
<ul class="simple">
<li><p>Add more domain tools and observe how the agent routes between model replies and tool calls.</p></li>
<li><p>Swap providers to compare cost, latency, and quality for your workload.</p></li>
<li><p>Explore the richer examples in the repo for RAG and multi-tool workflows.</p></li>
</ul>
</section>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../index.html">dllmforge</a></h1>









<search id="searchbox" style="display: none" role="search">
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" placeholder="Search"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script><h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">Tutorials:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="LLM_tutorial.html">Tutorial LLM capabilities of DLLMForge</a></li>
<li class="toctree-l1"><a class="reference internal" href="RAG_tutorial.html">Open Source RAG Pipeline Tutorial</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Building a Simple Agent with DLLMForge</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="#step-by-step-implementation">Step-by-Step Implementation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="tutorial_advanced_agent.html">Tutorial: Advanced Water Management Agent</a></li>
<li class="toctree-l1"><a class="reference internal" href="Information_extraction_tutorial.html">Information Extraction with LLMs Tutorial</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Background:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../background/LLM_explained.html">LLM Explained</a></li>
<li class="toctree-l1"><a class="reference internal" href="../background/RAGS_explained.html">Retrieval-Augmented Generation (RAG)</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../_autosummary/dllmforge.html">dllmforge</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
      <li>Previous: <a href="RAG_tutorial.html" title="previous chapter">Open Source RAG Pipeline Tutorial</a></li>
      <li>Next: <a href="tutorial_advanced_agent.html" title="next chapter">Tutorial: Advanced Water Management Agent</a></li>
  </ul></li>
</ul>
</div>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;2023-2025, dllmforge team.
      
    </div>

    

    
  </body>
</html>