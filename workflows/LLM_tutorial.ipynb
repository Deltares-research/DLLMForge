{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af122186",
   "metadata": {},
   "source": [
    "# Tutorial: LLM Capabilities of DLLMForge\n",
    "\n",
    "This tutorial demonstrates how to use a simple LLM to ask questions using DLLMForge.\n",
    "\n",
    "There are different APIs available to use LLMs from OpenAI, Mistral, Azure OpenAI or Deltares hosted models.\n",
    "\n",
    "There are three different ways to use LLMs using:\n",
    "\n",
    "- **LlamaIndexAPI** - Containing LlamaIndex framework integration with OpenAI, Azure OpenAI and Mistral models.\n",
    "- **LangchainAPI** - Containing LangChain framework integration with OpenAI, Azure OpenAI and Mistral models.\n",
    "- **DeltaresOllamaLLM** - Containing Deltares hosted models.\n",
    "\n",
    "For the OpenAI and Mistral, a `.env` file is needed with the API keys.\n",
    "For the Deltares hosted models, no API key is needed, but you need to be on the Deltares network or VPN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f103797f",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "To use the OpenAI model, the following environment variables are needed in a `.env` file:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73b49cb",
   "metadata": {},
   "source": [
    "### OpenAI Environment Variables\n",
    "\n",
    "```\n",
    "OPENAI_API_KEY=your_openai_api_key\n",
    "OPENAI_MODEL_NAME=gpt-4  # or other available models\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ed339b",
   "metadata": {},
   "source": [
    "### Azure OpenAI Environment Variables\n",
    "\n",
    "```\n",
    "AZURE_OPENAI_API_KEY=your_azure_openai_api_key\n",
    "AZURE_OPENAI_ENDPOINT=your_azure_openai_endpoint\n",
    "AZURE_OPENAI_DEPLOYMENT_NAME=your_deployment_name\n",
    "AZURE_OPENAI_API_VERSION=your_api_version\n",
    "AZURE_OPENAI_MODEL_NAME=gpt-4  # or other available models\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ea4497",
   "metadata": {},
   "source": [
    "### Mistral Environment Variables\n",
    "\n",
    "```\n",
    "MISTRAL_API_KEY=your_mistral_api_key\n",
    "MISTRAL_MODEL_NAME=mistral-7b-instruct-v0.1  # or other available models\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a213abb",
   "metadata": {},
   "source": [
    "## 2. Initialize LLM with LlamaIndex API\n",
    "\n",
    "First, we initialize the LLM using the LlamaIndex API with different providers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddb445a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dllmforge.llamaindex_api import LlamaIndexAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d25375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI API\n",
    "api_llama_openai = LlamaIndexAPI(model_provider=\"openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1a7816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Mistral API\n",
    "api_llama_mistral = LlamaIndexAPI(model_provider=\"mistral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f02b73d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Azure OpenAI API\n",
    "api_llama_azure = LlamaIndexAPI(model_provider=\"azure-openai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840c8aac",
   "metadata": {},
   "source": [
    "## 3. Initialize LLM with LangChain API\n",
    "\n",
    "Alternatively, you can use the LangChain API with the same providers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa5a7d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dllmforge.langchain_api import LangchainAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43e002f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI API\n",
    "api_langchain_openai = LangchainAPI(model_provider=\"openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bfaf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Mistral API\n",
    "api_langchain_mistral = LangchainAPI(model_provider=\"mistral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58501e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Azure OpenAI API\n",
    "api_langchain_azure = LangchainAPI(model_provider=\"azure-openai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3736ad08",
   "metadata": {},
   "source": [
    "## 4. Initialize LLM with Deltares Hosted Models\n",
    "\n",
    "For Deltares hosted models, you need to be on the Deltares network or VPN. No API key is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37dcaf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dllmforge.LLMs.Deltares_LLMs import DeltaresOllamaLLM\n",
    "\n",
    "# Initialize Deltares hosted model\n",
    "base_url = \"https://chat-api.directory.intra\"\n",
    "model_name = \"llama3.1:70b\"  # or other available models\n",
    "llm = DeltaresOllamaLLM(base_url=base_url, model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3152427",
   "metadata": {},
   "source": [
    "## 5. Define Messages for Chat Completion\n",
    "\n",
    "All of the classes have a method `chat_completion` to ask a question to the LLM.\n",
    "\n",
    "The method takes a dictionary of messages as input and returns the response from the LLM.\n",
    "The dictionary of messages should contain a list of messages with the role and content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "288c907d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the messages\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is the capital of France?\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf8fb12",
   "metadata": {},
   "source": [
    "## 6. Ask Questions Using LlamaIndex API\n",
    "\n",
    "Now we can use the initialized LlamaIndex API to ask questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4e293c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://openaicoastal.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaIndex OpenAI Response: {'response': 'The capital of France is Paris.', 'model': 'azure-openai', 'usage': None}\n"
     ]
    }
   ],
   "source": [
    "# Using LlamaIndex API with OpenAI\n",
    "response_llama_openai = api_llama_azure.chat_completion(messages)\n",
    "print(\"LlamaIndex OpenAI Response:\", response_llama_openai)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423b2a79",
   "metadata": {},
   "source": [
    "## 7. Ask Questions Using LangChain API\n",
    "\n",
    "Similarly, we can use the LangChain API to ask questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e931895",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://openaicoastal.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2024-12-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain OpenAI Response: {'response': 'The capital of France is Paris.', 'model': 'azure-openai', 'usage': {'prompt_tokens': None, 'completion_tokens': None, 'total_tokens': None}}\n"
     ]
    }
   ],
   "source": [
    "# Using LangChain API with OpenAI\n",
    "response_langchain_openai = api_langchain_azure.chat_completion(messages)\n",
    "print(\"LangChain OpenAI Response:\", response_langchain_openai)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32404aa1",
   "metadata": {},
   "source": [
    "## 8. Ask Questions Using Deltares Models\n",
    "\n",
    "And we can use the Deltares hosted model to ask questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b9e1365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltares Model Response: {'choices': [{'message': {'role': 'assistant', 'content': 'The capital of France is Paris.'}, 'finish_reason': 'stop', 'done': True}], 'model': 'llama3.1:70b', 'usage': {'prompt_tokens': 29, 'completion_tokens': 8, 'total_tokens': 37}}\n"
     ]
    }
   ],
   "source": [
    "# Using Deltares hosted model\n",
    "response_deltares = llm.chat_completion(messages)\n",
    "print(\"Deltares Model Response:\", response_deltares)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cf8522",
   "metadata": {},
   "source": [
    "## 9. Advanced: Using Temperature and Max Tokens Parameters\n",
    "\n",
    "For the Deltares hosted models, you can also define the `temperature` and `max_tokens` parameters in the `chat_completion` method.\n",
    "\n",
    "### Temperature Parameter\n",
    "The temperature parameter (between 0 and 1) controls the randomness of the output:\n",
    "- **Low temperature (closer to 0)**: Makes the output more focused, deterministic, and repetitive, as the model sticks to the most probable words. Ideal for tasks like factual summaries.\n",
    "- **High temperature (above 1)**: Makes the output more random, creative, and varied, as the model is more likely to choose less likely words. Better for creative writing or brainstorming.\n",
    "\n",
    "### Max Tokens Parameter\n",
    "The max_tokens parameter controls the maximum length of the output in tokens. It can be used to limit the response length and ensure that the output fits within specific constraints.\n",
    "\n",
    "### /no_think Flag\n",
    "To turn off the thinking process of the model, you can add the \"/no_think\" flag to the messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "da5b7944",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_recent = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \" Explain the concept of photosynthesis. \"}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94832065",
   "metadata": {},
   "source": [
    "With low temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "385009a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response with custom parameters: Photosynthesis is the process by which plants, algae, and some bacteria convert light energy from the sun into chemical energy in the form of organic compounds, such as glucose.\n",
      "\n",
      "Here's a simplified overview:\n",
      "\n",
      "**The Basic Equation:**\n",
      "\n",
      "6 CO2 (carbon dioxide) + 6 H2O (water) + Light Energy â†’ C6H12O6 (glucose) + 6 O2 (oxygen)\n",
      "\n",
      "**How it Works:**\n",
      "\n",
      "1. **Light Absorption**: Plants absorb light energy from the sun through specialized pigments such as chlorophyll.\n",
      "2. **Water and Carbon Dioxide Uptake**: Plants take in water from the soil and carbon dioxide from the air.\n",
      "3. **Conversion of Light Energy**: The absorbed light energy is used to convert carbon dioxide and water into glucose (a type of sugar) and oxygen.\n",
      "4. **Glucose Production**: Glucose is produced through a series of chemical reactions, which are fueled by the light energy.\n",
      "5. **Oxygen Release**: Oxygen is released as a byproduct of photosynthesis.\n",
      "\n",
      "**Importance of Photosynthesis:**\n",
      "\n",
      "Photosynthesis is essential for life on Earth because it:\n",
      "\n",
      "* Provides energy and organic compounds for plants to grow and develop\n",
      "* Produces oxygen, which is necessary for respiration in animals and humans\n",
      "* Supports the food chain by providing energy-rich molecules that are consumed by herbivores and omnivores\n",
      "\n",
      "In summary, photosynthesis is a vital process that allows plants to harness light energy from the sun and convert it into chemical energy, supporting life on our planet.\n",
      "\n",
      "Would you like me to elaborate on any specific aspect of photosynthesis?\n"
     ]
    }
   ],
   "source": [
    "# Example with temperature and max_tokens\n",
    "response_with_params = llm.chat_completion(\n",
    "    messages_recent, \n",
    "    temperature=0.1, \n",
    "    max_tokens=2000\n",
    ")\n",
    "print(\"Response with custom parameters:\", response_with_params['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b36b57d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response with custom parameters: I'd be delighted to explain the concept of photosynthesis.\n",
      "\n",
      "Photosynthesis is a fundamental biological process that occurs in plants, algae, and some types of bacteria. It's a complex process that involves converting light energy from the sun into chemical energy in the form of glucose (a type of sugar).\n",
      "\n",
      "Here's a simplified explanation:\n",
      "\n",
      "**The Key Players:**\n",
      "\n",
      "1. **Light Energy:** The energy from sunlight is absorbed by pigments like chlorophyll, which is present in specialized organelles called chloroplasts.\n",
      "2. **Water and Carbon Dioxide:** Water (H2O) and carbon dioxide (CO2) are the raw materials for photosynthesis.\n",
      "3. **Chloroplasts:** These tiny organelles contain the necessary structures for photosynthesis to occur.\n",
      "\n",
      "**The Process:**\n",
      "\n",
      "1. **Light-Dependent Reactions:** Light energy is absorbed by chlorophyll, which excites electrons that then transfer to a series of molecules in a chain reaction.\n",
      "2. **Water Oxidation:** Water molecules are split into oxygen (O2) and hydrogen ions, releasing energy that drives the next steps.\n",
      "3. **Calvin Cycle:** Carbon dioxide enters the cycle and is fixed into glucose through a series of enzyme-catalyzed reactions.\n",
      "\n",
      "**The End Products:**\n",
      "\n",
      "1. **Glucose (C6H12O6):** The sugar molecule produced during photosynthesis serves as an energy source for plants.\n",
      "2. **Oxygen (O2):** Oxygen is released as a byproduct into the atmosphere, making it available for respiration in animals and other organisms.\n",
      "\n",
      "**In Summary:** Photosynthesis is the remarkable process by which plants convert sunlight, water, and carbon dioxide into glucose and oxygen, ultimately supporting life on Earth!\n",
      "\n",
      "Was that explanation helpful? Do you have any questions about photosynthesis?\n"
     ]
    }
   ],
   "source": [
    "# Example with temperature and max_tokens\n",
    "response_with_params = llm.chat_completion(\n",
    "    messages_recent, \n",
    "    temperature=1.8, \n",
    "    max_tokens=2000\n",
    ")\n",
    "print(\"Response with custom parameters:\", response_with_params['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094a0299",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This tutorial demonstrated how to use different LLM APIs with DLLMForge:\n",
    "\n",
    "1. **LlamaIndex API** - For OpenAI, Mistral, and Azure OpenAI integration\n",
    "2. **LangChain API** - For OpenAI, Mistral, and Azure OpenAI integration  \n",
    "3. **Deltares Hosted Models** - For internal Deltares models (no API key needed)\n",
    "\n",
    "All APIs provide a consistent `chat_completion` method for asking questions to the LLMs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
