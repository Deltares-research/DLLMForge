{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82c669dd",
   "metadata": {},
   "source": [
    "# Information Extraction Tutorial:\n",
    "\n",
    "This tutorial demonstrates a complete end-to-end workflow for extracting structured information from documents using DLLMForge's Information Extraction tools.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "In this tutorial, as an example, we'll extract **machine learning project information** from research papers by:\n",
    "\n",
    "1. **Generating a Schema** - Automatically create a Pydantic schema for the data structure\n",
    "2. **Processing Documents** - Convert PDFs to text/images suitable for LLM processing\n",
    "3. **Extracting Information** - Use an LLM to extract structured data\n",
    "4. **Batch Processing** - Process multiple documents efficiently\n",
    "5. **Aggregating Results** - Combine results into a structured dataset\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "```bash\n",
    "pip install dllmforge\n",
    "```\n",
    "\n",
    "You'll also need:\n",
    "- API keys for your LLM provider (OpenAI, Azure OpenAI, Anthropic, etc.)\n",
    "- PDF research papers to process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd519a3",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Libraries\n",
    "\n",
    "First, let's import all the necessary modules from DLLMForge and Python's standard library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c2b49cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All imports successful!\n"
     ]
    }
   ],
   "source": [
    "from dllmforge.IE_agent_schema_generator import SchemaGenerator\n",
    "from dllmforge.IE_agent_document_processor import DocumentProcessor\n",
    "from dllmforge.IE_agent_extractor import InfoExtractor\n",
    "from dllmforge.langchain_api import LangchainAPI\n",
    "from pathlib import Path\n",
    "import importlib.util\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "print(\"✓ All imports successful!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafdf8f7",
   "metadata": {},
   "source": [
    "## Step 2: Initialize the LLM\n",
    "\n",
    "**Important:** Make sure you have set up your API keys as environment variables before running this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ca1e6a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use LangchainAPI\n",
    "llm_api = LangchainAPI(\n",
    "    model_provider=\"azure-openai\",  # Change to \"openai\" or \"anthropic\" as needed\n",
    "    temperature=0.1                 # Low temperature for more consistent extraction\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c26a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use Deltares hosted open source model\n",
    "# from dllmforge.LLMs.Deltares_LLMs import DeltaresOllamaLLM\n",
    "\n",
    "# # Initialize Deltares hosted model\n",
    "# base_url = \"https://chat-api.directory.intra\"\n",
    "# model_name = \"llama3.1:70b\"  # or other available models\n",
    "# llm_api = DeltaresOllamaLLM(base_url=base_url, model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b36dd3",
   "metadata": {},
   "source": [
    "## Step 3: Generate Extraction Schema\n",
    "\n",
    "The first step is to define what information we want to extract. Instead of manually writing a Pydantic schema, we'll use the `SchemaGenerator` to automatically create one based on a task description. After generation, you can check and modify the schema generated.\n",
    "\n",
    "Of course, you can also manually write your own Pydantic schema and save it as python file in generated_schemas folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1d2d3f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document loader initialized with support for: .pdf, .docx, .xlsx, .xls, .csv\n",
      "No example document provided\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://openai-floods.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-08-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema saved to generated_schemas\\schema.py\n",
      "✓ Schema generated and saved to generated_schemas\\schema.py\n",
      "\n",
      "Generated Schema Preview:\n",
      "============================================================\n",
      "from pydantic import BaseModel, Field\n",
      "from typing import Optional\n",
      "\n",
      "class MachineLearningProject(BaseModel):\n",
      "    project_name: str = Field(..., description=\"The name of the machine learning project.\")\n",
      "    model_used: str = Field(..., description=\"The machine learning model used in the project.\")\n",
      "    contact_person: Optional[str] = Field(None, description=\"The contact person for the project, if available.\")\n",
      "\n",
      "    class Config:\n",
      "        schema_extra = {\n",
      "            \"example\": {\n",
      "                \"proje...\n"
     ]
    }
   ],
   "source": [
    "# Define what information we want to extract\n",
    "schema_task_description = (\n",
    "    \"Extract machine learning project information from papers, information including project name, machine learning model used, contact person\"\n",
    ")\n",
    "\n",
    "# Create directory for generated schema\n",
    "schema_dir = Path(\"generated_schemas\")\n",
    "schema_dir.mkdir(exist_ok=True)\n",
    "schema_file = schema_dir / \"schema.py\"\n",
    "\n",
    "# Create schema generator with direct arguments\n",
    "schema_generator = SchemaGenerator(\n",
    "    llm_api=llm_api,\n",
    "    task_description=schema_task_description,\n",
    "    output_path=str(schema_file)\n",
    ")\n",
    "\n",
    "# Generate and save the schema\n",
    "schema_code = schema_generator.generate_schema()\n",
    "schema_generator.save_schema(schema_code)\n",
    "\n",
    "print(f\"✓ Schema generated and saved to {schema_file}\")\n",
    "print(\"\\nGenerated Schema Preview:\")\n",
    "print(\"=\" * 60)\n",
    "print(schema_code[:500] + \"...\")  # Show first 500 characters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03ee65d",
   "metadata": {},
   "source": [
    "### Load the Generated Schema\n",
    "\n",
    "Now we need to dynamically load the generated schema class so we can use it for extraction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8d0b3c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Schema class loaded: MachineLearningProject\n",
      "\n",
      "Schema fields:\n",
      "  - project_name: <class 'str'>\n",
      "  - model_used: <class 'str'>\n",
      "  - contact_person: typing.Optional[str]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\deng_jg\\work\\toy\\pizza_course_test\\venv\\lib\\site-packages\\pydantic\\_internal\\_config.py:383: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Find the class name in the generated schema\n",
    "class_matches = re.finditer(r\"class\\s+(\\w+)\\s*\\(\", schema_code)\n",
    "class_names = [match.group(1) for match in class_matches]\n",
    "schema_class_name = class_names[-1]  # Get the last (main) class\n",
    "\n",
    "# Dynamically load the schema module\n",
    "spec = importlib.util.spec_from_file_location(\"temp_module\", schema_file)\n",
    "module = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(module)\n",
    "SchemaClass = getattr(module, schema_class_name)\n",
    "\n",
    "print(f\"✓ Schema class loaded: {schema_class_name}\")\n",
    "print(f\"\\nSchema fields:\")\n",
    "for field_name, field_info in SchemaClass.model_fields.items():\n",
    "    print(f\"  - {field_name}: {field_info.annotation}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc61a5c6",
   "metadata": {},
   "source": [
    "## Step 4: Configure Paths\n",
    "\n",
    "Set up the input and output directories for your documents.\n",
    "\n",
    "**Note:** Update these paths to match your local setup!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3ea580e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Input directory:  menu_pdfs\n",
      "✓ Output directory: output\n"
     ]
    }
   ],
   "source": [
    "# Define input and output directories\n",
    "# UPDATE THESE PATHS TO MATCH YOUR SETUP\n",
    "document_input_dir = r\"menu_pdfs\"  # Directory containing your files\n",
    "document_output_dir = r\"output\"          # Where results will be saved\n",
    "\n",
    "print(f\"✓ Input directory:  {document_input_dir}\")\n",
    "print(f\"✓ Output directory: {document_output_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dfc977",
   "metadata": {},
   "source": [
    "## Step 5: Configure Document Processor\n",
    "\n",
    "The `DocumentProcessor` handles converting documents into text or image format that can be processed by the LLM.\n",
    "\n",
    "Key parameters:\n",
    "- `input_dir`: Where your documents are located\n",
    "- `file_pattern`: Pattern to match files (e.g., \"*.pdf\")\n",
    "- `output_type`: \"text\" for text extraction or \"image\" for vision models\n",
    "- `output_dir`: Where processed documents will be saved\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0258b635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document loader initialized with support for: .pdf, .docx, .xlsx, .xls, .csv\n",
      "✓ Document processor configured\n",
      "  - Ready to process documents in: menu_pdfs\n"
     ]
    }
   ],
   "source": [
    "# Create document processor\n",
    "doc_processor = DocumentProcessor(\n",
    "    input_dir=document_input_dir,\n",
    "    file_pattern=\"*.pdf\",           # Match all PDF files\n",
    "    output_type=\"text\",              # Extract as text (use \"image\" for vision models)\n",
    "    output_dir=document_output_dir\n",
    ")\n",
    "\n",
    "print(f\"✓ Document processor configured\")\n",
    "print(f\"  - Ready to process documents in: {document_input_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2220bc90",
   "metadata": {},
   "source": [
    "## Step 6: Create the Information Extractor\n",
    "\n",
    "The `InfoExtractor` is the main component that orchestrates the extraction process. It combines:\n",
    "- The schema (what to extract)\n",
    "- The LLM (how to extract)\n",
    "- The document processor (preparing documents)\n",
    "- Custom instructions (system prompt)\n",
    "\n",
    "Key parameters:\n",
    "- `chunk_size`: Maximum tokens per chunk (important for long documents)\n",
    "- `chunk_overlap`: Overlap between chunks to avoid missing information at boundaries\n",
    "- `system_prompt`: Instructions for the LLM on how to extract information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "48ceb6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define extraction instructions\n",
    "system_prompt = \"\"\"Extract machine learning project information from papers.\n",
    "Only extract explicitly stated values. Use None for fields not found.\n",
    "Be precise with numeric values and units.\"\"\"\n",
    "\n",
    "# Create the extractor\n",
    "extractor = InfoExtractor(\n",
    "    output_schema=SchemaClass,              # The schema we generated earlier\n",
    "    llm_api=llm_api,                        # The LLM we initialized\n",
    "    system_prompt=system_prompt,            # Custom extraction instructions\n",
    "    chunk_size=80000,                       # Max tokens per chunk\n",
    "    chunk_overlap=10000,                    # Overlap between chunks\n",
    "    doc_processor=doc_processor,            # Document processor handles PDF conversion\n",
    "    document_output_type=\"text\"             # Extract as text\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17480edc",
   "metadata": {},
   "source": [
    "## Step 7: Extract from a Single Document\n",
    "\n",
    "Let's start by processing a single document to see how the extraction works. This is useful for:\n",
    "- Testing your setup\n",
    "- Inspecting the quality of extracted data\n",
    "- Debugging extraction issues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e3bd6b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Optimizing geotechnical in-situ site investigations using Deep Reinforcement Learning.pdf\n",
      "✓ Document converted to text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://openai-floods.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-08-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Extracted 1 result(s)\n",
      "Results saved to output\\Optimizing geotechnical in-situ site investigations using Deep Reinforcement Learning_extracted.json\n"
     ]
    }
   ],
   "source": [
    "# UPDATE THIS PATH to point to one of your PDF files\n",
    "single_doc_path = Path(document_input_dir) / \"Optimizing geotechnical in-situ site investigations using Deep Reinforcement Learning.pdf\"\n",
    "\n",
    "# Check if the file exists before processing\n",
    "if single_doc_path.exists():\n",
    "    print(f\"Processing: {single_doc_path.name}\")\n",
    "    \n",
    "    # Step 1: Process the file (PDF -> text)\n",
    "    doc = extractor.doc_processor.process_file(single_doc_path)\n",
    "    print(f\"✓ Document converted to text\")\n",
    "    \n",
    "    # Step 2: Extract structured information\n",
    "    results = extractor.process_document(doc)\n",
    "    print(f\"✓ Extracted {len(results)} result(s)\")\n",
    "    \n",
    "    # Save the results\n",
    "    output_path = Path(document_output_dir) / f\"{single_doc_path.stem}_extracted.json\"\n",
    "    extractor.save_results(results, output_path)\n",
    "    \n",
    "else:\n",
    "    print(f\"⚠ File not found: {single_doc_path}\")\n",
    "    print(\"Please update the 'single_doc_path' variable with a valid file path.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dcd4a5",
   "metadata": {},
   "source": [
    "## Step 8: Batch Process All Documents\n",
    "\n",
    "Now that we've verified the extraction works for a single document, let's process all documents in the input directory!\n",
    "\n",
    "The `process_all()` method automatically:\n",
    "1. Finds all files matching the pattern\n",
    "2. Processes each file (e.g., PDF → text)\n",
    "3. Extracts information from each document\n",
    "4. Saves all results to a single combined JSON file\n",
    "\n",
    "**New Feature:** By default, all results are now saved to a single `all_extracted.json` file with a `_source_document` field to identify which document each extraction came from. You can also save individual files by using `process_all(save_individual=True)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b081f02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 files to process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\deng_jg\\work\\toy\\pizza_course_test\\venv\\lib\\site-packages\\pydantic\\_internal\\_config.py:383: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n",
      "INFO:httpx:HTTP Request: POST https://openai-floods.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-08-01-preview \"HTTP/1.1 200 OK\"\n",
      "c:\\Users\\deng_jg\\work\\toy\\pizza_course_test\\venv\\lib\\site-packages\\pydantic\\_internal\\_config.py:383: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n",
      "INFO:httpx:HTTP Request: POST https://openai-floods.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-08-01-preview \"HTTP/1.1 200 OK\"\n",
      "c:\\Users\\deng_jg\\work\\toy\\pizza_course_test\\venv\\lib\\site-packages\\pydantic\\_internal\\_config.py:383: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n",
      "INFO:httpx:HTTP Request: POST https://openai-floods.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-08-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to output\\all_extracted.json\n",
      "\n",
      "✓ Combined results saved to output\\all_extracted.json\n",
      "  Total extractions: 3\n",
      "\n",
      "============================================================\n",
      "✓ All documents processed and extracted!\n",
      "============================================================\n",
      "\n",
      "Check output directory: output\n",
      "All results are combined in a single JSON file\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Process all documents and save to a single combined JSON file\n",
    "    # By default, results are saved to \"all_extracted.json\"\n",
    "    # You can customize the output filename with: combined_output_name=\"my_results.json\"\n",
    "    extractor.process_all()\n",
    "    \n",
    "    # If you want to save BOTH individual files AND a combined file, use:\n",
    "    # extractor.process_all(save_individual=True)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"✓ All documents processed and extracted!\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nCheck output directory: {document_output_dir}\")\n",
    "    print(\"All results are combined in a single JSON file\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n⚠ Error during batch processing: {e}\")\n",
    "    print(\"This might happen if the input directory doesn't exist or has no PDF files.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04e7a5e",
   "metadata": {},
   "source": [
    "## What's Next...\n",
    "\n",
    "Post-processing of the raw extracted information might be needed, such as checking duplications, combining instances extracted from different chunks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
