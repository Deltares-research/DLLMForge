<!DOCTYPE html>

<html lang="en" data-content_root="./">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>dllmforge package &#8212; dllmforge  documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=5ecbeea2" />
    <link rel="stylesheet" type="text/css" href="_static/basic.css?v=686e5160" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css?v=27fed22d" />
    <script src="_static/documentation_options.js?v=5929fcd5"></script>
    <script src="_static/doctools.js?v=9bcbadda"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="dllmforge-package">
<h1>dllmforge package<a class="headerlink" href="#dllmforge-package" title="Link to this heading">¶</a></h1>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Link to this heading">¶</a></h2>
</section>
<section id="module-dllmforge.agent_core">
<span id="dllmforge-agent-core-module"></span><h2>dllmforge.agent_core module<a class="headerlink" href="#module-dllmforge.agent_core" title="Link to this heading">¶</a></h2>
<p>Simple agent core for DLLMForge - Clean LangGraph utilities.</p>
<p>This module provides simple, elegant utilities for creating LangGraph agents
following the pattern established in water_management_agent_simple.py.</p>
<dl class="py function">
<dt class="sig sig-object py" id="dllmforge.agent_core.tool">
<span class="sig-prename descclassname"><span class="pre">dllmforge.agent_core.</span></span><span class="sig-name descname"><span class="pre">tool</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">func</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/agent_core.html#tool"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.agent_core.tool" title="Link to this definition">¶</a></dt>
<dd><p>DLLMForge wrapper around LangChain’s &#64;tool decorator.</p>
<p>This decorator provides a consistent interface for creating tools
within the DLLMForge ecosystem while maintaining compatibility
with LangChain’s tool system.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>func</strong> – Function to be converted into a tool</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Tool function that can be used with SimpleAgent</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dllmforge.agent_core.SimpleAgent">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dllmforge.agent_core.</span></span><span class="sig-name descname"><span class="pre">SimpleAgent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">system_message</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_provider</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'azure-openai'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">llm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_text_tool_routing</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_tool_iterations</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">3</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/agent_core.html#SimpleAgent"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.agent_core.SimpleAgent" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Simple agent class for LangGraph workflows.</p>
<p>Initialize a simple LangGraph agent.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>system_message</strong> – System message for the agent</p></li>
<li><p><strong>temperature</strong> – LLM temperature setting</p></li>
<li><p><strong>model_provider</strong> – LLM provider (“azure-openai”, “openai”, “mistral”)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.agent_core.SimpleAgent.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">system_message</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_provider</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'azure-openai'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">llm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_text_tool_routing</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_tool_iterations</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">3</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/agent_core.html#SimpleAgent.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.agent_core.SimpleAgent.__init__" title="Link to this definition">¶</a></dt>
<dd><p>Initialize a simple LangGraph agent.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>system_message</strong> – System message for the agent</p></li>
<li><p><strong>temperature</strong> – LLM temperature setting</p></li>
<li><p><strong>model_provider</strong> – LLM provider (“azure-openai”, “openai”, “mistral”)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.agent_core.SimpleAgent.add_tool">
<span class="sig-name descname"><span class="pre">add_tool</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tool_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/dllmforge/agent_core.html#SimpleAgent.add_tool"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.agent_core.SimpleAgent.add_tool" title="Link to this definition">¶</a></dt>
<dd><p>Add a tool to the agent.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>tool_func</strong> – Function decorated with &#64;tool</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.agent_core.SimpleAgent.add_node">
<span class="sig-name descname"><span class="pre">add_node</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/dllmforge/agent_core.html#SimpleAgent.add_node"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.agent_core.SimpleAgent.add_node" title="Link to this definition">¶</a></dt>
<dd><p>Add a node to the workflow.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> – Node name</p></li>
<li><p><strong>func</strong> – Node function</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.agent_core.SimpleAgent.add_edge">
<span class="sig-name descname"><span class="pre">add_edge</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">from_node</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">to_node</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/dllmforge/agent_core.html#SimpleAgent.add_edge"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.agent_core.SimpleAgent.add_edge" title="Link to this definition">¶</a></dt>
<dd><p>Add a simple edge between nodes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>from_node</strong> – Source node</p></li>
<li><p><strong>to_node</strong> – Target node</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.agent_core.SimpleAgent.add_conditional_edge">
<span class="sig-name descname"><span class="pre">add_conditional_edge</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">from_node</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">condition_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/dllmforge/agent_core.html#SimpleAgent.add_conditional_edge"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.agent_core.SimpleAgent.add_conditional_edge" title="Link to this definition">¶</a></dt>
<dd><p>Add a conditional edge.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>from_node</strong> – Source node</p></li>
<li><p><strong>condition_func</strong> – Function that determines routing</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.agent_core.SimpleAgent.create_simple_workflow">
<span class="sig-name descname"><span class="pre">create_simple_workflow</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/dllmforge/agent_core.html#SimpleAgent.create_simple_workflow"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.agent_core.SimpleAgent.create_simple_workflow" title="Link to this definition">¶</a></dt>
<dd><p>Create a simple agent -&gt; tools workflow with optional text-based tool routing.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.agent_core.SimpleAgent.compile">
<span class="sig-name descname"><span class="pre">compile</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">checkpointer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/dllmforge/agent_core.html#SimpleAgent.compile"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.agent_core.SimpleAgent.compile" title="Link to this definition">¶</a></dt>
<dd><p>Compile the workflow.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.agent_core.SimpleAgent.process_query">
<span class="sig-name descname"><span class="pre">process_query</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">query</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/dllmforge/agent_core.html#SimpleAgent.process_query"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.agent_core.SimpleAgent.process_query" title="Link to this definition">¶</a></dt>
<dd><p>Process a query with the agent.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>query</strong> – User query</p></li>
<li><p><strong>stream</strong> – Whether to stream the response</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.agent_core.SimpleAgent.run_interactive">
<span class="sig-name descname"><span class="pre">run_interactive</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/dllmforge/agent_core.html#SimpleAgent.run_interactive"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.agent_core.SimpleAgent.run_interactive" title="Link to this definition">¶</a></dt>
<dd><p>Run the agent in interactive mode.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dllmforge.agent_core.create_basic_agent">
<span class="sig-prename descclassname"><span class="pre">dllmforge.agent_core.</span></span><span class="sig-name descname"><span class="pre">create_basic_agent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">system_message</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_provider</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'azure-openai'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="index.html#dllmforge.agent_core.SimpleAgent" title="dllmforge.agent_core.SimpleAgent"><span class="pre">SimpleAgent</span></a></span></span><a class="reference internal" href="_modules/dllmforge/agent_core.html#create_basic_agent"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.agent_core.create_basic_agent" title="Link to this definition">¶</a></dt>
<dd><p>Create a basic agent with standard setup.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>system_message</strong> – System message for the agent</p></li>
<li><p><strong>temperature</strong> – LLM temperature</p></li>
<li><p><strong>model_provider</strong> – LLM provider (“azure-openai”, “openai”, “mistral”)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Configured agent instance</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="index.html#dllmforge.agent_core.SimpleAgent" title="dllmforge.agent_core.SimpleAgent">SimpleAgent</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dllmforge.agent_core.create_echo_tool">
<span class="sig-prename descclassname"><span class="pre">dllmforge.agent_core.</span></span><span class="sig-name descname"><span class="pre">create_echo_tool</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/agent_core.html#create_echo_tool"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.agent_core.create_echo_tool" title="Link to this definition">¶</a></dt>
<dd><p>Create a simple echo tool for testing.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dllmforge.agent_core.create_basic_tools">
<span class="sig-prename descclassname"><span class="pre">dllmforge.agent_core.</span></span><span class="sig-name descname"><span class="pre">create_basic_tools</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Callable</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/dllmforge/agent_core.html#create_basic_tools"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.agent_core.create_basic_tools" title="Link to this definition">¶</a></dt>
<dd><p>Create basic utility tools for testing.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>List of tool functions</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-dllmforge.anthropic_api">
<span id="dllmforge-anthropic-api-module"></span><h2>dllmforge.anthropic_api module<a class="headerlink" href="#module-dllmforge.anthropic_api" title="Link to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="dllmforge.anthropic_api.AnthropicAPI">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dllmforge.anthropic_api.</span></span><span class="sig-name descname"><span class="pre">AnthropicAPI</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">api_key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'claude-3-7-sonnet-20250219'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deployment_claude37</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deployment_claude35</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/anthropic_api.html#AnthropicAPI"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.anthropic_api.AnthropicAPI" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Class to interact with Anthropic’s Claude API.</p>
<p>Initialize the Anthropic API client with configuration.</p>
<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.anthropic_api.AnthropicAPI.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">api_key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'claude-3-7-sonnet-20250219'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deployment_claude37</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deployment_claude35</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/anthropic_api.html#AnthropicAPI.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.anthropic_api.AnthropicAPI.__init__" title="Link to this definition">¶</a></dt>
<dd><p>Initialize the Anthropic API client with configuration.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.anthropic_api.AnthropicAPI.check_server_status">
<span class="sig-name descname"><span class="pre">check_server_status</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/anthropic_api.html#AnthropicAPI.check_server_status"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.anthropic_api.AnthropicAPI.check_server_status" title="Link to this definition">¶</a></dt>
<dd><p>Check if the Anthropic API service is accessible.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.anthropic_api.AnthropicAPI.list_available_models">
<span class="sig-name descname"><span class="pre">list_available_models</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/anthropic_api.html#AnthropicAPI.list_available_models"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.anthropic_api.AnthropicAPI.list_available_models" title="Link to this definition">¶</a></dt>
<dd><p>List available models from Anthropic.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.anthropic_api.AnthropicAPI.send_test_message">
<span class="sig-name descname"><span class="pre">send_test_message</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'Hello,</span> <span class="pre">how</span> <span class="pre">are</span> <span class="pre">you?'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/anthropic_api.html#AnthropicAPI.send_test_message"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.anthropic_api.AnthropicAPI.send_test_message" title="Link to this definition">¶</a></dt>
<dd><p>Send a test message to the model and get a response.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.anthropic_api.AnthropicAPI.chat_completion">
<span class="sig-name descname"><span class="pre">chat_completion</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.7</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_tokens</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/anthropic_api.html#AnthropicAPI.chat_completion"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.anthropic_api.AnthropicAPI.chat_completion" title="Link to this definition">¶</a></dt>
<dd><p>Get a chat completion from the model.</p>
</dd></dl>

</dd></dl>

</section>
<section id="module-dllmforge.langchain_api">
<span id="dllmforge-langchain-api-module"></span><h2>dllmforge.langchain_api module<a class="headerlink" href="#module-dllmforge.langchain_api" title="Link to this heading">¶</a></h2>
<p>Create LLM object and api calls from langchain, including Azure and non-Azure models.
We use openai and mistral models for examples.
An overview of available langchain chat models: <a class="reference external" href="https://python.langchain.com/docs/integrations/chat/">https://python.langchain.com/docs/integrations/chat/</a></p>
<dl class="py class">
<dt class="sig sig-object py" id="dllmforge.langchain_api.LangchainAPI">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dllmforge.langchain_api.</span></span><span class="sig-name descname"><span class="pre">LangchainAPI</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_provider</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'azure-openai'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_base</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_version</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deployment_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/langchain_api.html#LangchainAPI"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.langchain_api.LangchainAPI" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Class to interact with various LLM providers using Langchain.</p>
<p>Initialize the Langchain API client with specified configuration.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_provider</strong> (<em>str</em>) – Provider of model to use. Options are:
- “azure-openai”: Use Azure OpenAI
- “openai”: Use OpenAI
- “mistral”: Use Mistral</p></li>
<li><p><strong>temperature</strong> (<em>float</em>) – Temperature setting for the model (0.0 to 1.0)</p></li>
<li><p><strong>api_key</strong> (<em>str</em>) – API key for the provider</p></li>
<li><p><strong>api_base</strong> (<em>str</em>) – API base URL (for Azure)</p></li>
<li><p><strong>api_version</strong> (<em>str</em>) – API version (for Azure)</p></li>
<li><p><strong>deployment_name</strong> (<em>str</em>) – Deployment name (for Azure)</p></li>
<li><p><strong>model_name</strong> (<em>str</em>) – Model name (for OpenAI/Mistral)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.langchain_api.LangchainAPI.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_provider</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'azure-openai'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_base</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_version</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deployment_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/langchain_api.html#LangchainAPI.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.langchain_api.LangchainAPI.__init__" title="Link to this definition">¶</a></dt>
<dd><p>Initialize the Langchain API client with specified configuration.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_provider</strong> (<em>str</em>) – Provider of model to use. Options are:
- “azure-openai”: Use Azure OpenAI
- “openai”: Use OpenAI
- “mistral”: Use Mistral</p></li>
<li><p><strong>temperature</strong> (<em>float</em>) – Temperature setting for the model (0.0 to 1.0)</p></li>
<li><p><strong>api_key</strong> (<em>str</em>) – API key for the provider</p></li>
<li><p><strong>api_base</strong> (<em>str</em>) – API base URL (for Azure)</p></li>
<li><p><strong>api_version</strong> (<em>str</em>) – API version (for Azure)</p></li>
<li><p><strong>deployment_name</strong> (<em>str</em>) – Deployment name (for Azure)</p></li>
<li><p><strong>model_name</strong> (<em>str</em>) – Model name (for OpenAI/Mistral)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.langchain_api.LangchainAPI.check_server_status">
<span class="sig-name descname"><span class="pre">check_server_status</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/langchain_api.html#LangchainAPI.check_server_status"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.langchain_api.LangchainAPI.check_server_status" title="Link to this definition">¶</a></dt>
<dd><p>Check if the LLM service is accessible.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.langchain_api.LangchainAPI.send_test_message">
<span class="sig-name descname"><span class="pre">send_test_message</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'Hello,</span> <span class="pre">how</span> <span class="pre">are</span> <span class="pre">you?'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/langchain_api.html#LangchainAPI.send_test_message"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.langchain_api.LangchainAPI.send_test_message" title="Link to this definition">¶</a></dt>
<dd><p>Send a test message to the model and get a response.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>prompt</strong> (<em>str</em>) – The prompt string to send.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Dictionary containing the response and metadata.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.langchain_api.LangchainAPI.chat_completion">
<span class="sig-name descname"><span class="pre">chat_completion</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_tokens</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/langchain_api.html#LangchainAPI.chat_completion"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.langchain_api.LangchainAPI.chat_completion" title="Link to this definition">¶</a></dt>
<dd><p>Get a chat completion from the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>messages</strong> (<em>list</em>) – List of message tuples (role, content)</p></li>
<li><p><strong>temperature</strong> (<em>float</em>) – Optional temperature override</p></li>
<li><p><strong>max_tokens</strong> (<em>int</em>) – Optional max tokens override</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Dictionary containing the response and metadata.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.langchain_api.LangchainAPI.ask_with_retriever">
<span class="sig-name descname"><span class="pre">ask_with_retriever</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">question</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retriever</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/langchain_api.html#LangchainAPI.ask_with_retriever"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.langchain_api.LangchainAPI.ask_with_retriever" title="Link to this definition">¶</a></dt>
<dd><p>Ask a question using the retriever to get context.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>question</strong> (<em>str</em>) – The question to ask.</p></li>
<li><p><strong>retriever</strong> – A rag retriever object that can retrieve relevant context.</p></li>
<li><p><strong>**kwargs</strong> – Additional keyword arguments to pass to the LLM (e.g., temperature, max_tokens).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The response from the LLM.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-dllmforge.llamaindex_api">
<span id="dllmforge-llamaindex-api-module"></span><h2>dllmforge.llamaindex_api module<a class="headerlink" href="#module-dllmforge.llamaindex_api" title="Link to this heading">¶</a></h2>
<p>Create LLM object and API calls using llama_index, including Azure and non-Azure models.
We use openai and mistral models for examples.
An overview of available llama_index LLMs: <a class="reference external" href="https://docs.llamaindex.ai/en/stable/module_guides/models/llms/modules/">https://docs.llamaindex.ai/en/stable/module_guides/models/llms/modules/</a></p>
<dl class="py class">
<dt class="sig sig-object py" id="dllmforge.llamaindex_api.LlamaIndexAPI">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dllmforge.llamaindex_api.</span></span><span class="sig-name descname"><span class="pre">LlamaIndexAPI</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_provider</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'azure-openai'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_base</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_version</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deployment_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/llamaindex_api.html#LlamaIndexAPI"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.llamaindex_api.LlamaIndexAPI" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Class to interact with various LLM providers using LlamaIndex.</p>
<p>Initialize the LlamaIndex API client with specified configuration.
:param model_provider: Provider of model to use. Options are:</p>
<blockquote>
<div><ul class="simple">
<li><p>“azure-openai”: Use Azure OpenAI</p></li>
<li><p>“openai”: Use OpenAI</p></li>
<li><p>“mistral”: Use Mistral</p></li>
</ul>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>temperature</strong> (<em>float</em>) – Temperature setting for the model (0.0 to 1.0)</p></li>
<li><p><strong>api_key</strong> (<em>str</em>) – API key for the provider</p></li>
<li><p><strong>api_base</strong> (<em>str</em>) – API base URL (for Azure)</p></li>
<li><p><strong>api_version</strong> (<em>str</em>) – API version (for Azure)</p></li>
<li><p><strong>deployment_name</strong> (<em>str</em>) – Deployment name (for Azure)</p></li>
<li><p><strong>model_name</strong> (<em>str</em>) – Model name (for OpenAI/Mistral)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.llamaindex_api.LlamaIndexAPI.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_provider</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'azure-openai'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_base</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_version</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deployment_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/llamaindex_api.html#LlamaIndexAPI.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.llamaindex_api.LlamaIndexAPI.__init__" title="Link to this definition">¶</a></dt>
<dd><p>Initialize the LlamaIndex API client with specified configuration.
:param model_provider: Provider of model to use. Options are:</p>
<blockquote>
<div><ul class="simple">
<li><p>“azure-openai”: Use Azure OpenAI</p></li>
<li><p>“openai”: Use OpenAI</p></li>
<li><p>“mistral”: Use Mistral</p></li>
</ul>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>temperature</strong> (<em>float</em>) – Temperature setting for the model (0.0 to 1.0)</p></li>
<li><p><strong>api_key</strong> (<em>str</em>) – API key for the provider</p></li>
<li><p><strong>api_base</strong> (<em>str</em>) – API base URL (for Azure)</p></li>
<li><p><strong>api_version</strong> (<em>str</em>) – API version (for Azure)</p></li>
<li><p><strong>deployment_name</strong> (<em>str</em>) – Deployment name (for Azure)</p></li>
<li><p><strong>model_name</strong> (<em>str</em>) – Model name (for OpenAI/Mistral)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.llamaindex_api.LlamaIndexAPI.check_server_status">
<span class="sig-name descname"><span class="pre">check_server_status</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/llamaindex_api.html#LlamaIndexAPI.check_server_status"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.llamaindex_api.LlamaIndexAPI.check_server_status" title="Link to this definition">¶</a></dt>
<dd><p>Check if the LLM service is accessible.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.llamaindex_api.LlamaIndexAPI.send_test_message">
<span class="sig-name descname"><span class="pre">send_test_message</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'Hello,</span> <span class="pre">how</span> <span class="pre">are</span> <span class="pre">you?'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/llamaindex_api.html#LlamaIndexAPI.send_test_message"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.llamaindex_api.LlamaIndexAPI.send_test_message" title="Link to this definition">¶</a></dt>
<dd><p>Send a test message to the model and get a response.
:param prompt: The prompt string to send.
:type prompt: str</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Dictionary containing the response and metadata.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.llamaindex_api.LlamaIndexAPI.chat_completion">
<span class="sig-name descname"><span class="pre">chat_completion</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_tokens</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/llamaindex_api.html#LlamaIndexAPI.chat_completion"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.llamaindex_api.LlamaIndexAPI.chat_completion" title="Link to this definition">¶</a></dt>
<dd><p>Get a chat completion from the model.
:param messages: List of message dicts or tuples (role, content)
:type messages: list
:param temperature: Optional temperature override
:type temperature: float
:param max_tokens: Optional max tokens override
:type max_tokens: int</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Dictionary containing the response and metadata.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>dict</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-dllmforge.openai_api">
<span id="dllmforge-openai-api-module"></span><h2>dllmforge.openai_api module<a class="headerlink" href="#module-dllmforge.openai_api" title="Link to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="dllmforge.openai_api.OpenAIAPI">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dllmforge.openai_api.</span></span><span class="sig-name descname"><span class="pre">OpenAIAPI</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">api_key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_base</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_version</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deployment_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'gpt-4o'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embedding_deployment</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'text-embedding-3-large'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/openai_api.html#OpenAIAPI"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.openai_api.OpenAIAPI" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Class to interact with Azure OpenAI API.</p>
<p>Initialize the OpenAI API client with Azure configuration.</p>
<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.openai_api.OpenAIAPI.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">api_key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_base</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_version</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deployment_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'gpt-4o'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embedding_deployment</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'text-embedding-3-large'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/openai_api.html#OpenAIAPI.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.openai_api.OpenAIAPI.__init__" title="Link to this definition">¶</a></dt>
<dd><p>Initialize the OpenAI API client with Azure configuration.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.openai_api.OpenAIAPI.check_server_status">
<span class="sig-name descname"><span class="pre">check_server_status</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/openai_api.html#OpenAIAPI.check_server_status"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.openai_api.OpenAIAPI.check_server_status" title="Link to this definition">¶</a></dt>
<dd><p>Check if the Azure OpenAI service is accessible.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.openai_api.OpenAIAPI.list_available_models">
<span class="sig-name descname"><span class="pre">list_available_models</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/openai_api.html#OpenAIAPI.list_available_models"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.openai_api.OpenAIAPI.list_available_models" title="Link to this definition">¶</a></dt>
<dd><p>List available models from Azure OpenAI.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.openai_api.OpenAIAPI.send_test_message">
<span class="sig-name descname"><span class="pre">send_test_message</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'Hello,</span> <span class="pre">how</span> <span class="pre">are</span> <span class="pre">you?'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/openai_api.html#OpenAIAPI.send_test_message"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.openai_api.OpenAIAPI.send_test_message" title="Link to this definition">¶</a></dt>
<dd><p>Send a test message to the model and get a response.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.openai_api.OpenAIAPI.get_embeddings">
<span class="sig-name descname"><span class="pre">get_embeddings</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/openai_api.html#OpenAIAPI.get_embeddings"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.openai_api.OpenAIAPI.get_embeddings" title="Link to this definition">¶</a></dt>
<dd><p>Get embeddings for the given text using Azure OpenAI.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.openai_api.OpenAIAPI.chat_completion">
<span class="sig-name descname"><span class="pre">chat_completion</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.7</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_tokens</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">800</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/openai_api.html#OpenAIAPI.chat_completion"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.openai_api.OpenAIAPI.chat_completion" title="Link to this definition">¶</a></dt>
<dd><p>Get a chat completion from the model.</p>
</dd></dl>

</dd></dl>

</section>
<section id="module-dllmforge.rag_embedding">
<span id="dllmforge-rag-embedding-module"></span><h2>dllmforge.rag_embedding module<a class="headerlink" href="#module-dllmforge.rag_embedding" title="Link to this heading">¶</a></h2>
<p>This module provides embedding functionality for RAG (Retrieval-Augmented Generation) pipelines.
It can be used to 1) vectorize document chunks, and 2) vectorize user queries.
The module uses Azure OpenAI embeddings model as an example of using hosted embedding APIs. Note you need
Azure OpenAI service and a deployed embedding model on Azure to use this module.</p>
<dl class="py class">
<dt class="sig sig-object py" id="dllmforge.rag_embedding.AzureOpenAIEmbeddingModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dllmforge.rag_embedding.</span></span><span class="sig-name descname"><span class="pre">AzureOpenAIEmbeddingModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'text-embedding-3-large'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_base</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deployment_name_embeddings</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_version</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/rag_embedding.html#AzureOpenAIEmbeddingModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_embedding.AzureOpenAIEmbeddingModel" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Class for embedding queries and document chunks using Azure OpenAI Embeddings.</p>
<p>Initialize the embedding model using provided arguments or environment variables for Azure OpenAI.
:param model: Name of the embedding model to use
:param api_base: Azure OpenAI API base URL
:param deployment_name_embeddings: Azure OpenAI deployment name for embeddings
:param api_key: Azure OpenAI API key
:param api_version: Azure OpenAI API version</p>
<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.rag_embedding.AzureOpenAIEmbeddingModel.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'text-embedding-3-large'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_base</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deployment_name_embeddings</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_version</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/rag_embedding.html#AzureOpenAIEmbeddingModel.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_embedding.AzureOpenAIEmbeddingModel.__init__" title="Link to this definition">¶</a></dt>
<dd><p>Initialize the embedding model using provided arguments or environment variables for Azure OpenAI.
:param model: Name of the embedding model to use
:param api_base: Azure OpenAI API base URL
:param deployment_name_embeddings: Azure OpenAI deployment name for embeddings
:param api_key: Azure OpenAI API key
:param api_version: Azure OpenAI API version</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.rag_embedding.AzureOpenAIEmbeddingModel.validate_embedding">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">validate_embedding</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">embedding</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="reference internal" href="_modules/dllmforge/rag_embedding.html#AzureOpenAIEmbeddingModel.validate_embedding"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_embedding.AzureOpenAIEmbeddingModel.validate_embedding" title="Link to this definition">¶</a></dt>
<dd><p>Validate that the embedding is not empty.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.rag_embedding.AzureOpenAIEmbeddingModel.encode_filename">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">encode_filename</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">filename</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="reference internal" href="_modules/dllmforge/rag_embedding.html#AzureOpenAIEmbeddingModel.encode_filename"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_embedding.AzureOpenAIEmbeddingModel.encode_filename" title="Link to this definition">¶</a></dt>
<dd><p>Encode filename to be safe for Azure Cognitive Search document keys.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.rag_embedding.AzureOpenAIEmbeddingModel.embed">
<span class="sig-name descname"><span class="pre">embed</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">query_or_chunks</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/dllmforge/rag_embedding.html#AzureOpenAIEmbeddingModel.embed"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_embedding.AzureOpenAIEmbeddingModel.embed" title="Link to this definition">¶</a></dt>
<dd><p>Embed a single query string or a list of document chunks.
:param query_or_chunks: A string (query) or a list of dictionaries (document chunks)</p>
<blockquote>
<div><p>Each dictionary should have keys: “text”, “file_name”, “page_number”</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><p>list of floats (embedding vector)
For document chunks: list of dictionaries with keys: “chunk_id”, “chunk”, “page_number”,</p>
<blockquote>
<div><p>”file_name”, “text_vector”</p>
</div></blockquote>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>For a string query</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-dllmforge.rag_embedding_open_source">
<span id="dllmforge-rag-embedding-open-source-module"></span><h2>dllmforge.rag_embedding_open_source module<a class="headerlink" href="#module-dllmforge.rag_embedding_open_source" title="Link to this heading">¶</a></h2>
<p>This module provides embedding functionality for RAG (Retrieval-Augmented Generation) pipelines.
It can be used to 1) vectorize document chunks, and 2) vectorize user queries.
The module uses Azure OpenAI embeddings model as an example of using hosted embedding APIs. Note you need
Azure OpenAI service and a deployed embedding model on Azure to use this module.</p>
<dl class="py class">
<dt class="sig sig-object py" id="dllmforge.rag_embedding_open_source.LangchainHFEmbeddingModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dllmforge.rag_embedding_open_source.</span></span><span class="sig-name descname"><span class="pre">LangchainHFEmbeddingModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'sentence-transformers/all-MiniLM-L6-v2'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/rag_embedding_open_source.html#LangchainHFEmbeddingModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_embedding_open_source.LangchainHFEmbeddingModel" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Class for embedding queries and document chunks using LangChain’s HuggingFaceEmbeddings.</p>
<p>Initialize the HuggingFaceEmbeddings from LangChain.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>model_name</strong> – Name or path of the Hugging Face model (default: “sentence-transformers/all-MiniLM-L6-v2”).</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.rag_embedding_open_source.LangchainHFEmbeddingModel.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'sentence-transformers/all-MiniLM-L6-v2'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/rag_embedding_open_source.html#LangchainHFEmbeddingModel.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_embedding_open_source.LangchainHFEmbeddingModel.__init__" title="Link to this definition">¶</a></dt>
<dd><p>Initialize the HuggingFaceEmbeddings from LangChain.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>model_name</strong> – Name or path of the Hugging Face model (default: “sentence-transformers/all-MiniLM-L6-v2”).</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.rag_embedding_open_source.LangchainHFEmbeddingModel.validate_embedding">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">validate_embedding</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">embedding</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="reference internal" href="_modules/dllmforge/rag_embedding_open_source.html#LangchainHFEmbeddingModel.validate_embedding"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_embedding_open_source.LangchainHFEmbeddingModel.validate_embedding" title="Link to this definition">¶</a></dt>
<dd><p>Validate that the embedding vector is non-empty and numeric.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.rag_embedding_open_source.LangchainHFEmbeddingModel.embed">
<span class="sig-name descname"><span class="pre">embed</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">query_or_chunks</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/dllmforge/rag_embedding_open_source.html#LangchainHFEmbeddingModel.embed"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_embedding_open_source.LangchainHFEmbeddingModel.embed" title="Link to this definition">¶</a></dt>
<dd><p>Embed a single query string or a list of document chunks.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>query_or_chunks</strong> – A string (query) or list of dicts with keys:
“text”, “file_name”, “page_number”.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>list of floats (vector embedding).
- For document chunks: list of dicts with keys:</p>
<blockquote>
<div><p>”chunk_id”, “chunk”, “page_number”, “file_name”, “text_vector”.</p>
</div></blockquote>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><ul class="simple">
<li><p>For a string query</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-dllmforge.rag_evaluation">
<span id="dllmforge-rag-evaluation-module"></span><h2>dllmforge.rag_evaluation module<a class="headerlink" href="#module-dllmforge.rag_evaluation" title="Link to this heading">¶</a></h2>
<p>RAGAS Evaluation Module for DLLMForge</p>
<p>This module provides comprehensive evaluation metrics for RAG (Retrieval-Augmented Generation)
pipelines using RAGAS-inspired metrics without requiring external dashboards or services.</p>
<p>The module evaluates four key aspects of RAG systems:
1. Context Precision -
2. Context Recall - measures the ability to retrieve all necessary information
3. Faithfulness - measures factual accuracy and absence of hallucinations
4. Answer Relevancy - measures how relevant and to-the-point answers are</p>
<p>All evaluations are performed using LLMs to provide human-like assessment without requiring
annotated datasets.</p>
<dl class="py class">
<dt class="sig sig-object py" id="dllmforge.rag_evaluation.EvaluationResult">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dllmforge.rag_evaluation.</span></span><span class="sig-name descname"><span class="pre">EvaluationResult</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">metric_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">score</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">explanation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">details</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/rag_evaluation.html#EvaluationResult"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_evaluation.EvaluationResult" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Container for evaluation results.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="dllmforge.rag_evaluation.EvaluationResult.metric_name">
<span class="sig-name descname"><span class="pre">metric_name</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><a class="headerlink" href="#dllmforge.rag_evaluation.EvaluationResult.metric_name" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dllmforge.rag_evaluation.EvaluationResult.score">
<span class="sig-name descname"><span class="pre">score</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><a class="headerlink" href="#dllmforge.rag_evaluation.EvaluationResult.score" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dllmforge.rag_evaluation.EvaluationResult.explanation">
<span class="sig-name descname"><span class="pre">explanation</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><a class="headerlink" href="#dllmforge.rag_evaluation.EvaluationResult.explanation" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dllmforge.rag_evaluation.EvaluationResult.details">
<span class="sig-name descname"><span class="pre">details</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#dllmforge.rag_evaluation.EvaluationResult.details" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.rag_evaluation.EvaluationResult.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">metric_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">score</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">explanation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">details</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dllmforge.rag_evaluation.EvaluationResult.__init__" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dllmforge.rag_evaluation.RAGEvaluationResult">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dllmforge.rag_evaluation.</span></span><span class="sig-name descname"><span class="pre">RAGEvaluationResult</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">context_precision</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#dllmforge.rag_evaluation.EvaluationResult" title="dllmforge.rag_evaluation.EvaluationResult"><span class="pre">EvaluationResult</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">context_recall</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#dllmforge.rag_evaluation.EvaluationResult" title="dllmforge.rag_evaluation.EvaluationResult"><span class="pre">EvaluationResult</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">faithfulness</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#dllmforge.rag_evaluation.EvaluationResult" title="dllmforge.rag_evaluation.EvaluationResult"><span class="pre">EvaluationResult</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">answer_relevancy</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#dllmforge.rag_evaluation.EvaluationResult" title="dllmforge.rag_evaluation.EvaluationResult"><span class="pre">EvaluationResult</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">ragas_score</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">evaluation_time</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metadata</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/rag_evaluation.html#RAGEvaluationResult"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_evaluation.RAGEvaluationResult" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Container for complete RAG evaluation results.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="dllmforge.rag_evaluation.RAGEvaluationResult.context_precision">
<span class="sig-name descname"><span class="pre">context_precision</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="#dllmforge.rag_evaluation.EvaluationResult" title="dllmforge.rag_evaluation.EvaluationResult"><span class="pre">EvaluationResult</span></a></em><a class="headerlink" href="#dllmforge.rag_evaluation.RAGEvaluationResult.context_precision" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dllmforge.rag_evaluation.RAGEvaluationResult.context_recall">
<span class="sig-name descname"><span class="pre">context_recall</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="#dllmforge.rag_evaluation.EvaluationResult" title="dllmforge.rag_evaluation.EvaluationResult"><span class="pre">EvaluationResult</span></a></em><a class="headerlink" href="#dllmforge.rag_evaluation.RAGEvaluationResult.context_recall" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dllmforge.rag_evaluation.RAGEvaluationResult.faithfulness">
<span class="sig-name descname"><span class="pre">faithfulness</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="#dllmforge.rag_evaluation.EvaluationResult" title="dllmforge.rag_evaluation.EvaluationResult"><span class="pre">EvaluationResult</span></a></em><a class="headerlink" href="#dllmforge.rag_evaluation.RAGEvaluationResult.faithfulness" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dllmforge.rag_evaluation.RAGEvaluationResult.answer_relevancy">
<span class="sig-name descname"><span class="pre">answer_relevancy</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="#dllmforge.rag_evaluation.EvaluationResult" title="dllmforge.rag_evaluation.EvaluationResult"><span class="pre">EvaluationResult</span></a></em><a class="headerlink" href="#dllmforge.rag_evaluation.RAGEvaluationResult.answer_relevancy" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dllmforge.rag_evaluation.RAGEvaluationResult.ragas_score">
<span class="sig-name descname"><span class="pre">ragas_score</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><a class="headerlink" href="#dllmforge.rag_evaluation.RAGEvaluationResult.ragas_score" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dllmforge.rag_evaluation.RAGEvaluationResult.evaluation_time">
<span class="sig-name descname"><span class="pre">evaluation_time</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><a class="headerlink" href="#dllmforge.rag_evaluation.RAGEvaluationResult.evaluation_time" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dllmforge.rag_evaluation.RAGEvaluationResult.metadata">
<span class="sig-name descname"><span class="pre">metadata</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#dllmforge.rag_evaluation.RAGEvaluationResult.metadata" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.rag_evaluation.RAGEvaluationResult.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">context_precision</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#dllmforge.rag_evaluation.EvaluationResult" title="dllmforge.rag_evaluation.EvaluationResult"><span class="pre">EvaluationResult</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">context_recall</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#dllmforge.rag_evaluation.EvaluationResult" title="dllmforge.rag_evaluation.EvaluationResult"><span class="pre">EvaluationResult</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">faithfulness</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#dllmforge.rag_evaluation.EvaluationResult" title="dllmforge.rag_evaluation.EvaluationResult"><span class="pre">EvaluationResult</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">answer_relevancy</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#dllmforge.rag_evaluation.EvaluationResult" title="dllmforge.rag_evaluation.EvaluationResult"><span class="pre">EvaluationResult</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">ragas_score</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">evaluation_time</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metadata</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dllmforge.rag_evaluation.RAGEvaluationResult.__init__" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dllmforge.rag_evaluation.RAGEvaluator">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dllmforge.rag_evaluation.</span></span><span class="sig-name descname"><span class="pre">RAGEvaluator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">llm_provider</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deltares_llm</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DeltaresOllamaLLM</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_base</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_version</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deployment_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/rag_evaluation.html#RAGEvaluator"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_evaluation.RAGEvaluator" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>RAGAS-inspired evaluator for RAG pipelines.</p>
<p>This evaluator provides four key metrics:
- Context Precision:
- Context Recall: Measures the ability to retrieve all necessary information
- Faithfulness: Measures factual accuracy and absence of hallucinations
- Answer Relevancy: Measures how relevant and to-the-point answers are</p>
<p>Initialize the RAG evaluator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>llm_provider</strong> – LLM provider to use (“openai”, “anthropic”, “deltares” or “auto”)</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.rag_evaluation.RAGEvaluator.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">llm_provider</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deltares_llm</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DeltaresOllamaLLM</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_base</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_version</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deployment_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/rag_evaluation.html#RAGEvaluator.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_evaluation.RAGEvaluator.__init__" title="Link to this definition">¶</a></dt>
<dd><p>Initialize the RAG evaluator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>llm_provider</strong> – LLM provider to use (“openai”, “anthropic”, “deltares” or “auto”)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.rag_evaluation.RAGEvaluator.evaluate_context_relevancy">
<span class="sig-name descname"><span class="pre">evaluate_context_relevancy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">question</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retrieved_contexts</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#dllmforge.rag_evaluation.EvaluationResult" title="dllmforge.rag_evaluation.EvaluationResult"><span class="pre">EvaluationResult</span></a></span></span><a class="reference internal" href="_modules/dllmforge/rag_evaluation.html#RAGEvaluator.evaluate_context_relevancy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_evaluation.RAGEvaluator.evaluate_context_relevancy" title="Link to this definition">¶</a></dt>
<dd><p>Evaluate the relevancy of retrieved contexts to the question.</p>
<p>This metric measures the signal-to-noise ratio in the retrieved contexts.
It identifies which sentences from the context are actually needed to answer the question.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>question</strong> – The user’s question</p></li>
<li><p><strong>retrieved_contexts</strong> – List of retrieved context chunks</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>EvaluationResult with score and explanation</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.rag_evaluation.RAGEvaluator.evaluate_context_precision">
<span class="sig-name descname"><span class="pre">evaluate_context_precision</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">question</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retrieved_contexts</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ground_truth_answer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_k</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#dllmforge.rag_evaluation.EvaluationResult" title="dllmforge.rag_evaluation.EvaluationResult"><span class="pre">EvaluationResult</span></a></span></span><a class="reference internal" href="_modules/dllmforge/rag_evaluation.html#RAGEvaluator.evaluate_context_precision"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_evaluation.RAGEvaluator.evaluate_context_precision" title="Link to this definition">¶</a></dt>
<dd><p>Evaluate Context Precision&#64;k following the Ragas implementation.</p>
<p>For each of the top-k retrieved chunks, the LLM judges whether the chunk
supports the reference answer. Average Precision (AP) is then computed as:</p>
<blockquote>
<div><p>AP = sum(Precision&#64;i * rel_i) / (# relevant chunks)</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>question</strong> – The question to evaluate.</p></li>
<li><p><strong>reference_answer</strong> – The correct or gold answer.</p></li>
<li><p><strong>retrieved_contexts</strong> – Ranked list of retrieved chunks.</p></li>
<li><p><strong>top_k</strong> – Number of top chunks to evaluate.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>EvaluationResult with precision&#64;k score and explanation.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.rag_evaluation.RAGEvaluator.evaluate_context_recall">
<span class="sig-name descname"><span class="pre">evaluate_context_recall</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">question</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retrieved_contexts</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ground_truth_answer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#dllmforge.rag_evaluation.EvaluationResult" title="dllmforge.rag_evaluation.EvaluationResult"><span class="pre">EvaluationResult</span></a></span></span><a class="reference internal" href="_modules/dllmforge/rag_evaluation.html#RAGEvaluator.evaluate_context_recall"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_evaluation.RAGEvaluator.evaluate_context_recall" title="Link to this definition">¶</a></dt>
<dd><p>Evaluate the recall of retrieved contexts against a ground truth answer.
This metric measures the ability of the retriever to retrieve all necessary information
needed to answer the question by checking if each statement from the ground truth
can be found in the retrieved context.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>question</strong> – The user’s question</p></li>
<li><p><strong>retrieved_contexts</strong> – List of retrieved context chunks</p></li>
<li><p><strong>ground_truth_answer</strong> – The reference answer to compare against</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>EvaluationResult with score and explanation</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.rag_evaluation.RAGEvaluator.evaluate_faithfulness">
<span class="sig-name descname"><span class="pre">evaluate_faithfulness</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">question</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">generated_answer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retrieved_contexts</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#dllmforge.rag_evaluation.EvaluationResult" title="dllmforge.rag_evaluation.EvaluationResult"><span class="pre">EvaluationResult</span></a></span></span><a class="reference internal" href="_modules/dllmforge/rag_evaluation.html#RAGEvaluator.evaluate_faithfulness"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_evaluation.RAGEvaluator.evaluate_faithfulness" title="Link to this definition">¶</a></dt>
<dd><p>Evaluate the faithfulness of the generated answer to the retrieved contexts.</p>
<p>This metric measures the factual accuracy of the generated answer by checking
if all statements in the answer are supported by the retrieved contexts.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>question</strong> – The user’s question</p></li>
<li><p><strong>generated_answer</strong> – The answer generated by the RAG system</p></li>
<li><p><strong>retrieved_contexts</strong> – List of retrieved context chunks</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>EvaluationResult with score and explanation</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.rag_evaluation.RAGEvaluator.evaluate_answer_relevancy">
<span class="sig-name descname"><span class="pre">evaluate_answer_relevancy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">question</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">generated_answer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#dllmforge.rag_evaluation.EvaluationResult" title="dllmforge.rag_evaluation.EvaluationResult"><span class="pre">EvaluationResult</span></a></span></span><a class="reference internal" href="_modules/dllmforge/rag_evaluation.html#RAGEvaluator.evaluate_answer_relevancy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_evaluation.RAGEvaluator.evaluate_answer_relevancy" title="Link to this definition">¶</a></dt>
<dd><p>Evaluate the relevancy of the generated answer to the question.
This metric measures how relevant and to-the-point the answer is by generating
probable questions that the answer could answer and computing similarity to the actual question.
:param question: The user’s question
:param generated_answer: The answer generated by the RAG system</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>EvaluationResult with score and explanation</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.rag_evaluation.RAGEvaluator.calculate_ragas_score">
<span class="sig-name descname"><span class="pre">calculate_ragas_score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">context_precision</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context_recall</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">faithfulness</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">answer_relevancy</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="reference internal" href="_modules/dllmforge/rag_evaluation.html#RAGEvaluator.calculate_ragas_score"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_evaluation.RAGEvaluator.calculate_ragas_score" title="Link to this definition">¶</a></dt>
<dd><p>Calculate the RAGAS score as the harmonic mean of all four metrics.
:param context_precision: Context precision score
:param context_recall: Context recall score
:param faithfulness: Faithfulness score
:param answer_relevancy: Answer relevancy score</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>RAGAS score (harmonic mean)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.rag_evaluation.RAGEvaluator.evaluate_rag_pipeline">
<span class="sig-name descname"><span class="pre">evaluate_rag_pipeline</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">question</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">generated_answer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retrieved_contexts</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ground_truth_answer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#dllmforge.rag_evaluation.RAGEvaluationResult" title="dllmforge.rag_evaluation.RAGEvaluationResult"><span class="pre">RAGEvaluationResult</span></a></span></span><a class="reference internal" href="_modules/dllmforge/rag_evaluation.html#RAGEvaluator.evaluate_rag_pipeline"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_evaluation.RAGEvaluator.evaluate_rag_pipeline" title="Link to this definition">¶</a></dt>
<dd><p>Evaluate a complete RAG pipeline using all four metrics.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>question</strong> – The user’s question</p></li>
<li><p><strong>generated_answer</strong> – The answer generated by the RAG system</p></li>
<li><p><strong>retrieved_contexts</strong> – List of retrieved context chunks</p></li>
<li><p><strong>ground_truth_answer</strong> – Optional ground truth answer for context recall evaluation</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Complete evaluation results</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.rag_evaluation.RAGEvaluator.print_evaluation_summary">
<span class="sig-name descname"><span class="pre">print_evaluation_summary</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">result</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#dllmforge.rag_evaluation.RAGEvaluationResult" title="dllmforge.rag_evaluation.RAGEvaluationResult"><span class="pre">RAGEvaluationResult</span></a></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/rag_evaluation.html#RAGEvaluator.print_evaluation_summary"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_evaluation.RAGEvaluator.print_evaluation_summary" title="Link to this definition">¶</a></dt>
<dd><p>Print a formatted summary of the evaluation results.
:param result: The evaluation results to summarize</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.rag_evaluation.RAGEvaluator.save_evaluation_results">
<span class="sig-name descname"><span class="pre">save_evaluation_results</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">result</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#dllmforge.rag_evaluation.RAGEvaluationResult" title="dllmforge.rag_evaluation.RAGEvaluationResult"><span class="pre">RAGEvaluationResult</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_file</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/rag_evaluation.html#RAGEvaluator.save_evaluation_results"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_evaluation.RAGEvaluator.save_evaluation_results" title="Link to this definition">¶</a></dt>
<dd><p>Save evaluation results to a JSON file.
:param result: The evaluation results to save
:param output_file: Path to the output JSON file</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dllmforge.rag_evaluation.evaluate_rag_response">
<span class="sig-prename descclassname"><span class="pre">dllmforge.rag_evaluation.</span></span><span class="sig-name descname"><span class="pre">evaluate_rag_response</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">question</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">generated_answer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retrieved_contexts</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ground_truth_answer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">llm_provider</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_results</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_file</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#dllmforge.rag_evaluation.RAGEvaluationResult" title="dllmforge.rag_evaluation.RAGEvaluationResult"><span class="pre">RAGEvaluationResult</span></a></span></span><a class="reference internal" href="_modules/dllmforge/rag_evaluation.html#evaluate_rag_response"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_evaluation.evaluate_rag_response" title="Link to this definition">¶</a></dt>
<dd><p>Convenience function to evaluate a RAG response.
:param question: The user’s question
:param generated_answer: The answer generated by the RAG system
:param retrieved_contexts: List of retrieved context chunks
:param ground_truth_answer: Optional ground truth answer for context recall evaluation
:param llm_provider: LLM provider to use (“openai”, “anthropic”, or “auto”)
:param save_results: Whether to save results to a file
:param output_file: Optional output file path</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Complete evaluation results</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-dllmforge.rag_preprocess_documents">
<span id="dllmforge-rag-preprocess-documents-module"></span><h2>dllmforge.rag_preprocess_documents module<a class="headerlink" href="#module-dllmforge.rag_preprocess_documents" title="Link to this heading">¶</a></h2>
<p>This module provides document preprocessing functionality for RAG (Retrieval-Augmented Generation) pipelines.
It includes document loading and text chunking for PDF files.</p>
<dl class="py class">
<dt class="sig sig-object py" id="dllmforge.rag_preprocess_documents.DocumentLoader">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dllmforge.rag_preprocess_documents.</span></span><span class="sig-name descname"><span class="pre">DocumentLoader</span></span><a class="reference internal" href="_modules/dllmforge/rag_preprocess_documents.html#DocumentLoader"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_preprocess_documents.DocumentLoader" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">ABC</span></code></p>
<p>Abstract base class for document loaders.</p>
<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.rag_preprocess_documents.DocumentLoader.load">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">load</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Path</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/dllmforge/rag_preprocess_documents.html#DocumentLoader.load"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_preprocess_documents.DocumentLoader.load" title="Link to this definition">¶</a></dt>
<dd><p>Load a document and return its contents as a list of (page_number, text) tuples.
:param file_path: Path to the document file</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>List of tuples containing (page_number, text) pairs</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dllmforge.rag_preprocess_documents.PDFLoader">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dllmforge.rag_preprocess_documents.</span></span><span class="sig-name descname"><span class="pre">PDFLoader</span></span><a class="reference internal" href="_modules/dllmforge/rag_preprocess_documents.html#PDFLoader"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_preprocess_documents.PDFLoader" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#dllmforge.rag_preprocess_documents.DocumentLoader" title="dllmforge.rag_preprocess_documents.DocumentLoader"><code class="xref py py-class docutils literal notranslate"><span class="pre">DocumentLoader</span></code></a></p>
<p>Loader for PDF documents using PyPDF2.</p>
<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.rag_preprocess_documents.PDFLoader.load">
<span class="sig-name descname"><span class="pre">load</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Path</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/dllmforge/rag_preprocess_documents.html#PDFLoader.load"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_preprocess_documents.PDFLoader.load" title="Link to this definition">¶</a></dt>
<dd><p>Load a PDF document and extract text from its pages.
:param file_path: Path to the PDF file</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple containing (pages_with_text, file_name) where pages_with_text is a list of (page_number, text) pairs</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dllmforge.rag_preprocess_documents.TextChunker">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dllmforge.rag_preprocess_documents.</span></span><span class="sig-name descname"><span class="pre">TextChunker</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">chunk_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">overlap_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">200</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/rag_preprocess_documents.html#TextChunker"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_preprocess_documents.TextChunker" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Class for chunking text into smaller segments with overlap.
For detailed information about chunking strategies in RAG applications, including:
- Why chunking is important
- How to choose chunk size and overlap
- Different splitting techniques
- Evaluation methods
See: <a class="reference external" href="https://www.mongodb.com/developer/products/atlas/choosing-chunking-strategy-rag/">https://www.mongodb.com/developer/products/atlas/choosing-chunking-strategy-rag/</a></p>
<p>Initialize the TextChunker.
:param chunk_size: Maximum size of each chunk in characters
:param overlap_size: Number of characters to overlap between chunks (recommended: 5-20% of chunk_size)</p>
<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.rag_preprocess_documents.TextChunker.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">chunk_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">overlap_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">200</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/rag_preprocess_documents.html#TextChunker.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_preprocess_documents.TextChunker.__init__" title="Link to this definition">¶</a></dt>
<dd><p>Initialize the TextChunker.
:param chunk_size: Maximum size of each chunk in characters
:param overlap_size: Number of characters to overlap between chunks (recommended: 5-20% of chunk_size)</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.rag_preprocess_documents.TextChunker.chunk_text">
<span class="sig-name descname"><span class="pre">chunk_text</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pages_with_text</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">file_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metadata</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/dllmforge/rag_preprocess_documents.html#TextChunker.chunk_text"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_preprocess_documents.TextChunker.chunk_text" title="Link to this definition">¶</a></dt>
<dd><p>Split text into chunks while preserving sentence boundaries.
:param pages_with_text: List of tuples containing (page_number, text) pairs
:param file_name: Name of the source file (optional)
:param metadata: Metadata information extracted from the document (optional)</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>{</dt><dd><p>‘text’: str,           # The chunk text
‘page_number’: int,    # Source page number
‘chunk_index’: int,    # Index of the chunk
‘total_chunks’: int,   # Total number of chunks from this document
‘file_name’: str       # Name of the source file</p>
</dd>
</dl>
<p>}</p>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>List of dictionaries containing chunks with metadata</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-dllmforge.rag_search_and_response">
<span id="dllmforge-rag-search-and-response-module"></span><h2>dllmforge.rag_search_and_response module<a class="headerlink" href="#module-dllmforge.rag_search_and_response" title="Link to this heading">¶</a></h2>
<p>This module provides “create index/vector-database”, “search” and “response”
functionality for RAG (Retrieval-Augmented Generation) pipelines.
Three steps are involved:
1. Create index/vector-database: create an index/vector-database on Azure AI search service.
1. Search: use Azure AI search service to retrieve relevant chunks from the vector database .
2. Response: use LLMs to generate a response to the user query based on the retrieved chunks.
The module uses Azure AI search service and Azure OpenAI service as an example of using hosted search
APIs and LLMs APIs. Note you need
Azure AI search service, Azure OpenAI service and a deployed LLM model on Azure to use this module.</p>
<p>The example demonstrates the whole pipeline of RAG, including:
1. Preprocess the documents to chunks.
2. Vectorize the chunks.
3. Create vector index and store the chunks in the vector database.
4. Search the vector database for relevant chunks.
5. Generate a response to the user query based on the retrieved chunks.</p>
<dl class="py class">
<dt class="sig sig-object py" id="dllmforge.rag_search_and_response.IndexManager">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dllmforge.rag_search_and_response.</span></span><span class="sig-name descname"><span class="pre">IndexManager</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">search_client_endpoint</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">search_api_key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">index_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embedding_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/rag_search_and_response.html#IndexManager"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_search_and_response.IndexManager" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.rag_search_and_response.IndexManager.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">search_client_endpoint</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">search_api_key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">index_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embedding_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/rag_search_and_response.html#IndexManager.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_search_and_response.IndexManager.__init__" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.rag_search_and_response.IndexManager.create_index">
<span class="sig-name descname"><span class="pre">create_index</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">api_base</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deployment_name_embeddings</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/rag_search_and_response.html#IndexManager.create_index"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_search_and_response.IndexManager.create_index" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.rag_search_and_response.IndexManager.upload_documents">
<span class="sig-name descname"><span class="pre">upload_documents</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">vectorized_chunks</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/rag_search_and_response.html#IndexManager.upload_documents"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_search_and_response.IndexManager.upload_documents" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dllmforge.rag_search_and_response.Retriever">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dllmforge.rag_search_and_response.</span></span><span class="sig-name descname"><span class="pre">Retriever</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">embedding_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">index_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">search_client_endpoint</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">search_api_key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/rag_search_and_response.html#Retriever"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_search_and_response.Retriever" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.rag_search_and_response.Retriever.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">embedding_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">index_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">search_client_endpoint</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">search_api_key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/rag_search_and_response.html#Retriever.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_search_and_response.Retriever.__init__" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.rag_search_and_response.Retriever.get_embeddings">
<span class="sig-name descname"><span class="pre">get_embeddings</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/rag_search_and_response.html#Retriever.get_embeddings"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_search_and_response.Retriever.get_embeddings" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.rag_search_and_response.Retriever.invoke">
<span class="sig-name descname"><span class="pre">invoke</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">query_text</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_k</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/rag_search_and_response.html#Retriever.invoke"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_search_and_response.Retriever.invoke" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dllmforge.rag_search_and_response.LLMResponder">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dllmforge.rag_search_and_response.</span></span><span class="sig-name descname"><span class="pre">LLMResponder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">llm</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/rag_search_and_response.html#LLMResponder"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_search_and_response.LLMResponder" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.rag_search_and_response.LLMResponder.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">llm</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/rag_search_and_response.html#LLMResponder.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_search_and_response.LLMResponder.__init__" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.rag_search_and_response.LLMResponder.augment_prompt_with_context">
<span class="sig-name descname"><span class="pre">augment_prompt_with_context</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">query_text</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">chunks</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/rag_search_and_response.html#LLMResponder.augment_prompt_with_context"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_search_and_response.LLMResponder.augment_prompt_with_context" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.rag_search_and_response.LLMResponder.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">query_text</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retrieved_chunks</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/rag_search_and_response.html#LLMResponder.generate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_search_and_response.LLMResponder.generate" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-dllmforge">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-dllmforge" title="Link to this heading">¶</a></h2>
<p>DLLMForge - Deltares LLM Forge Toolkit</p>
<p>A comprehensive toolkit for building and deploying LLM-based applications
with RAG capabilities, agentic workflows, and enterprise-grade features.</p>
<dl class="py class">
<dt class="sig sig-object py" id="dllmforge.SimpleAgent">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dllmforge.</span></span><span class="sig-name descname"><span class="pre">SimpleAgent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">system_message</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_provider</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'azure-openai'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">llm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_text_tool_routing</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_tool_iterations</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">3</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/agent_core.html#SimpleAgent"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.SimpleAgent" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Simple agent class for LangGraph workflows.</p>
<p>Initialize a simple LangGraph agent.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>system_message</strong> – System message for the agent</p></li>
<li><p><strong>temperature</strong> – LLM temperature setting</p></li>
<li><p><strong>model_provider</strong> – LLM provider (“azure-openai”, “openai”, “mistral”)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.SimpleAgent.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">system_message</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_provider</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'azure-openai'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">llm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_text_tool_routing</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_tool_iterations</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">3</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/agent_core.html#SimpleAgent.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.SimpleAgent.__init__" title="Link to this definition">¶</a></dt>
<dd><p>Initialize a simple LangGraph agent.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>system_message</strong> – System message for the agent</p></li>
<li><p><strong>temperature</strong> – LLM temperature setting</p></li>
<li><p><strong>model_provider</strong> – LLM provider (“azure-openai”, “openai”, “mistral”)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.SimpleAgent.add_tool">
<span class="sig-name descname"><span class="pre">add_tool</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tool_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/dllmforge/agent_core.html#SimpleAgent.add_tool"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.SimpleAgent.add_tool" title="Link to this definition">¶</a></dt>
<dd><p>Add a tool to the agent.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>tool_func</strong> – Function decorated with &#64;tool</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.SimpleAgent.add_node">
<span class="sig-name descname"><span class="pre">add_node</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/dllmforge/agent_core.html#SimpleAgent.add_node"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.SimpleAgent.add_node" title="Link to this definition">¶</a></dt>
<dd><p>Add a node to the workflow.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> – Node name</p></li>
<li><p><strong>func</strong> – Node function</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.SimpleAgent.add_edge">
<span class="sig-name descname"><span class="pre">add_edge</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">from_node</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">to_node</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/dllmforge/agent_core.html#SimpleAgent.add_edge"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.SimpleAgent.add_edge" title="Link to this definition">¶</a></dt>
<dd><p>Add a simple edge between nodes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>from_node</strong> – Source node</p></li>
<li><p><strong>to_node</strong> – Target node</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.SimpleAgent.add_conditional_edge">
<span class="sig-name descname"><span class="pre">add_conditional_edge</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">from_node</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">condition_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/dllmforge/agent_core.html#SimpleAgent.add_conditional_edge"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.SimpleAgent.add_conditional_edge" title="Link to this definition">¶</a></dt>
<dd><p>Add a conditional edge.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>from_node</strong> – Source node</p></li>
<li><p><strong>condition_func</strong> – Function that determines routing</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.SimpleAgent.create_simple_workflow">
<span class="sig-name descname"><span class="pre">create_simple_workflow</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/dllmforge/agent_core.html#SimpleAgent.create_simple_workflow"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.SimpleAgent.create_simple_workflow" title="Link to this definition">¶</a></dt>
<dd><p>Create a simple agent -&gt; tools workflow with optional text-based tool routing.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.SimpleAgent.compile">
<span class="sig-name descname"><span class="pre">compile</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">checkpointer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/dllmforge/agent_core.html#SimpleAgent.compile"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.SimpleAgent.compile" title="Link to this definition">¶</a></dt>
<dd><p>Compile the workflow.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.SimpleAgent.process_query">
<span class="sig-name descname"><span class="pre">process_query</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">query</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/dllmforge/agent_core.html#SimpleAgent.process_query"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.SimpleAgent.process_query" title="Link to this definition">¶</a></dt>
<dd><p>Process a query with the agent.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>query</strong> – User query</p></li>
<li><p><strong>stream</strong> – Whether to stream the response</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.SimpleAgent.run_interactive">
<span class="sig-name descname"><span class="pre">run_interactive</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/dllmforge/agent_core.html#SimpleAgent.run_interactive"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.SimpleAgent.run_interactive" title="Link to this definition">¶</a></dt>
<dd><p>Run the agent in interactive mode.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dllmforge.create_basic_agent">
<span class="sig-prename descclassname"><span class="pre">dllmforge.</span></span><span class="sig-name descname"><span class="pre">create_basic_agent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">system_message</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_provider</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'azure-openai'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="index.html#dllmforge.agent_core.SimpleAgent" title="dllmforge.agent_core.SimpleAgent"><span class="pre">SimpleAgent</span></a></span></span><a class="reference internal" href="_modules/dllmforge/agent_core.html#create_basic_agent"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.create_basic_agent" title="Link to this definition">¶</a></dt>
<dd><p>Create a basic agent with standard setup.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>system_message</strong> – System message for the agent</p></li>
<li><p><strong>temperature</strong> – LLM temperature</p></li>
<li><p><strong>model_provider</strong> – LLM provider (“azure-openai”, “openai”, “mistral”)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Configured agent instance</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#dllmforge.SimpleAgent" title="dllmforge.SimpleAgent">SimpleAgent</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dllmforge.create_basic_tools">
<span class="sig-prename descclassname"><span class="pre">dllmforge.</span></span><span class="sig-name descname"><span class="pre">create_basic_tools</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Callable</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/dllmforge/agent_core.html#create_basic_tools"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.create_basic_tools" title="Link to this definition">¶</a></dt>
<dd><p>Create basic utility tools for testing.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>List of tool functions</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dllmforge.AzureOpenAIEmbeddingModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dllmforge.</span></span><span class="sig-name descname"><span class="pre">AzureOpenAIEmbeddingModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'text-embedding-3-large'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_base</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deployment_name_embeddings</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_version</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/rag_embedding.html#AzureOpenAIEmbeddingModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.AzureOpenAIEmbeddingModel" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Class for embedding queries and document chunks using Azure OpenAI Embeddings.</p>
<p>Initialize the embedding model using provided arguments or environment variables for Azure OpenAI.
:param model: Name of the embedding model to use
:param api_base: Azure OpenAI API base URL
:param deployment_name_embeddings: Azure OpenAI deployment name for embeddings
:param api_key: Azure OpenAI API key
:param api_version: Azure OpenAI API version</p>
<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.AzureOpenAIEmbeddingModel.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'text-embedding-3-large'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_base</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deployment_name_embeddings</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_version</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/rag_embedding.html#AzureOpenAIEmbeddingModel.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.AzureOpenAIEmbeddingModel.__init__" title="Link to this definition">¶</a></dt>
<dd><p>Initialize the embedding model using provided arguments or environment variables for Azure OpenAI.
:param model: Name of the embedding model to use
:param api_base: Azure OpenAI API base URL
:param deployment_name_embeddings: Azure OpenAI deployment name for embeddings
:param api_key: Azure OpenAI API key
:param api_version: Azure OpenAI API version</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.AzureOpenAIEmbeddingModel.validate_embedding">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">validate_embedding</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">embedding</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="reference internal" href="_modules/dllmforge/rag_embedding.html#AzureOpenAIEmbeddingModel.validate_embedding"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.AzureOpenAIEmbeddingModel.validate_embedding" title="Link to this definition">¶</a></dt>
<dd><p>Validate that the embedding is not empty.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.AzureOpenAIEmbeddingModel.encode_filename">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">encode_filename</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">filename</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="reference internal" href="_modules/dllmforge/rag_embedding.html#AzureOpenAIEmbeddingModel.encode_filename"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.AzureOpenAIEmbeddingModel.encode_filename" title="Link to this definition">¶</a></dt>
<dd><p>Encode filename to be safe for Azure Cognitive Search document keys.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.AzureOpenAIEmbeddingModel.embed">
<span class="sig-name descname"><span class="pre">embed</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">query_or_chunks</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/dllmforge/rag_embedding.html#AzureOpenAIEmbeddingModel.embed"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.AzureOpenAIEmbeddingModel.embed" title="Link to this definition">¶</a></dt>
<dd><p>Embed a single query string or a list of document chunks.
:param query_or_chunks: A string (query) or a list of dictionaries (document chunks)</p>
<blockquote>
<div><p>Each dictionary should have keys: “text”, “file_name”, “page_number”</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><p>list of floats (embedding vector)
For document chunks: list of dictionaries with keys: “chunk_id”, “chunk”, “page_number”,</p>
<blockquote>
<div><p>”file_name”, “text_vector”</p>
</div></blockquote>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>For a string query</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dllmforge.PDFLoader">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dllmforge.</span></span><span class="sig-name descname"><span class="pre">PDFLoader</span></span><a class="reference internal" href="_modules/dllmforge/rag_preprocess_documents.html#PDFLoader"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.PDFLoader" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#dllmforge.rag_preprocess_documents.DocumentLoader" title="dllmforge.rag_preprocess_documents.DocumentLoader"><code class="xref py py-class docutils literal notranslate"><span class="pre">DocumentLoader</span></code></a></p>
<p>Loader for PDF documents using PyPDF2.</p>
<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.PDFLoader.load">
<span class="sig-name descname"><span class="pre">load</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Path</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/dllmforge/rag_preprocess_documents.html#PDFLoader.load"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.PDFLoader.load" title="Link to this definition">¶</a></dt>
<dd><p>Load a PDF document and extract text from its pages.
:param file_path: Path to the PDF file</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple containing (pages_with_text, file_name) where pages_with_text is a list of (page_number, text) pairs</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dllmforge.TextChunker">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dllmforge.</span></span><span class="sig-name descname"><span class="pre">TextChunker</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">chunk_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">overlap_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">200</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/rag_preprocess_documents.html#TextChunker"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.TextChunker" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Class for chunking text into smaller segments with overlap.
For detailed information about chunking strategies in RAG applications, including:
- Why chunking is important
- How to choose chunk size and overlap
- Different splitting techniques
- Evaluation methods
See: <a class="reference external" href="https://www.mongodb.com/developer/products/atlas/choosing-chunking-strategy-rag/">https://www.mongodb.com/developer/products/atlas/choosing-chunking-strategy-rag/</a></p>
<p>Initialize the TextChunker.
:param chunk_size: Maximum size of each chunk in characters
:param overlap_size: Number of characters to overlap between chunks (recommended: 5-20% of chunk_size)</p>
<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.TextChunker.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">chunk_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">overlap_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">200</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/rag_preprocess_documents.html#TextChunker.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.TextChunker.__init__" title="Link to this definition">¶</a></dt>
<dd><p>Initialize the TextChunker.
:param chunk_size: Maximum size of each chunk in characters
:param overlap_size: Number of characters to overlap between chunks (recommended: 5-20% of chunk_size)</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.TextChunker.chunk_text">
<span class="sig-name descname"><span class="pre">chunk_text</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pages_with_text</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">file_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metadata</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/dllmforge/rag_preprocess_documents.html#TextChunker.chunk_text"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.TextChunker.chunk_text" title="Link to this definition">¶</a></dt>
<dd><p>Split text into chunks while preserving sentence boundaries.
:param pages_with_text: List of tuples containing (page_number, text) pairs
:param file_name: Name of the source file (optional)
:param metadata: Metadata information extracted from the document (optional)</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>{</dt><dd><p>‘text’: str,           # The chunk text
‘page_number’: int,    # Source page number
‘chunk_index’: int,    # Index of the chunk
‘total_chunks’: int,   # Total number of chunks from this document
‘file_name’: str       # Name of the source file</p>
</dd>
</dl>
<p>}</p>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>List of dictionaries containing chunks with metadata</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dllmforge.IndexManager">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dllmforge.</span></span><span class="sig-name descname"><span class="pre">IndexManager</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">search_client_endpoint</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">search_api_key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">index_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embedding_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/rag_search_and_response.html#IndexManager"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.IndexManager" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.IndexManager.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">search_client_endpoint</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">search_api_key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">index_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embedding_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/rag_search_and_response.html#IndexManager.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.IndexManager.__init__" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.IndexManager.create_index">
<span class="sig-name descname"><span class="pre">create_index</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">api_base</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deployment_name_embeddings</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/rag_search_and_response.html#IndexManager.create_index"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.IndexManager.create_index" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.IndexManager.upload_documents">
<span class="sig-name descname"><span class="pre">upload_documents</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">vectorized_chunks</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/rag_search_and_response.html#IndexManager.upload_documents"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.IndexManager.upload_documents" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dllmforge.Retriever">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dllmforge.</span></span><span class="sig-name descname"><span class="pre">Retriever</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">embedding_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">index_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">search_client_endpoint</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">search_api_key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/rag_search_and_response.html#Retriever"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.Retriever" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.Retriever.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">embedding_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">index_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">search_client_endpoint</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">search_api_key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/rag_search_and_response.html#Retriever.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.Retriever.__init__" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.Retriever.get_embeddings">
<span class="sig-name descname"><span class="pre">get_embeddings</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/rag_search_and_response.html#Retriever.get_embeddings"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.Retriever.get_embeddings" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.Retriever.invoke">
<span class="sig-name descname"><span class="pre">invoke</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">query_text</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_k</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/rag_search_and_response.html#Retriever.invoke"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.Retriever.invoke" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dllmforge.LLMResponder">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dllmforge.</span></span><span class="sig-name descname"><span class="pre">LLMResponder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">llm</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/rag_search_and_response.html#LLMResponder"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.LLMResponder" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.LLMResponder.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">llm</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/rag_search_and_response.html#LLMResponder.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.LLMResponder.__init__" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.LLMResponder.augment_prompt_with_context">
<span class="sig-name descname"><span class="pre">augment_prompt_with_context</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">query_text</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">chunks</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/rag_search_and_response.html#LLMResponder.augment_prompt_with_context"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.LLMResponder.augment_prompt_with_context" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.LLMResponder.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">query_text</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retrieved_chunks</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/rag_search_and_response.html#LLMResponder.generate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.LLMResponder.generate" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dllmforge.RAGEvaluator">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dllmforge.</span></span><span class="sig-name descname"><span class="pre">RAGEvaluator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">llm_provider</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deltares_llm</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DeltaresOllamaLLM</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_base</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_version</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deployment_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/rag_evaluation.html#RAGEvaluator"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.RAGEvaluator" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>RAGAS-inspired evaluator for RAG pipelines.</p>
<p>This evaluator provides four key metrics:
- Context Precision:
- Context Recall: Measures the ability to retrieve all necessary information
- Faithfulness: Measures factual accuracy and absence of hallucinations
- Answer Relevancy: Measures how relevant and to-the-point answers are</p>
<p>Initialize the RAG evaluator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>llm_provider</strong> – LLM provider to use (“openai”, “anthropic”, “deltares” or “auto”)</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.RAGEvaluator.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">llm_provider</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deltares_llm</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DeltaresOllamaLLM</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_base</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_version</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deployment_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/rag_evaluation.html#RAGEvaluator.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.RAGEvaluator.__init__" title="Link to this definition">¶</a></dt>
<dd><p>Initialize the RAG evaluator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>llm_provider</strong> – LLM provider to use (“openai”, “anthropic”, “deltares” or “auto”)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.RAGEvaluator.evaluate_context_relevancy">
<span class="sig-name descname"><span class="pre">evaluate_context_relevancy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">question</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retrieved_contexts</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#dllmforge.rag_evaluation.EvaluationResult" title="dllmforge.rag_evaluation.EvaluationResult"><span class="pre">EvaluationResult</span></a></span></span><a class="reference internal" href="_modules/dllmforge/rag_evaluation.html#RAGEvaluator.evaluate_context_relevancy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.RAGEvaluator.evaluate_context_relevancy" title="Link to this definition">¶</a></dt>
<dd><p>Evaluate the relevancy of retrieved contexts to the question.</p>
<p>This metric measures the signal-to-noise ratio in the retrieved contexts.
It identifies which sentences from the context are actually needed to answer the question.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>question</strong> – The user’s question</p></li>
<li><p><strong>retrieved_contexts</strong> – List of retrieved context chunks</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>EvaluationResult with score and explanation</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.RAGEvaluator.evaluate_context_precision">
<span class="sig-name descname"><span class="pre">evaluate_context_precision</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">question</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retrieved_contexts</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ground_truth_answer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_k</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#dllmforge.rag_evaluation.EvaluationResult" title="dllmforge.rag_evaluation.EvaluationResult"><span class="pre">EvaluationResult</span></a></span></span><a class="reference internal" href="_modules/dllmforge/rag_evaluation.html#RAGEvaluator.evaluate_context_precision"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.RAGEvaluator.evaluate_context_precision" title="Link to this definition">¶</a></dt>
<dd><p>Evaluate Context Precision&#64;k following the Ragas implementation.</p>
<p>For each of the top-k retrieved chunks, the LLM judges whether the chunk
supports the reference answer. Average Precision (AP) is then computed as:</p>
<blockquote>
<div><p>AP = sum(Precision&#64;i * rel_i) / (# relevant chunks)</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>question</strong> – The question to evaluate.</p></li>
<li><p><strong>reference_answer</strong> – The correct or gold answer.</p></li>
<li><p><strong>retrieved_contexts</strong> – Ranked list of retrieved chunks.</p></li>
<li><p><strong>top_k</strong> – Number of top chunks to evaluate.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>EvaluationResult with precision&#64;k score and explanation.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.RAGEvaluator.evaluate_context_recall">
<span class="sig-name descname"><span class="pre">evaluate_context_recall</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">question</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retrieved_contexts</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ground_truth_answer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#dllmforge.rag_evaluation.EvaluationResult" title="dllmforge.rag_evaluation.EvaluationResult"><span class="pre">EvaluationResult</span></a></span></span><a class="reference internal" href="_modules/dllmforge/rag_evaluation.html#RAGEvaluator.evaluate_context_recall"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.RAGEvaluator.evaluate_context_recall" title="Link to this definition">¶</a></dt>
<dd><p>Evaluate the recall of retrieved contexts against a ground truth answer.
This metric measures the ability of the retriever to retrieve all necessary information
needed to answer the question by checking if each statement from the ground truth
can be found in the retrieved context.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>question</strong> – The user’s question</p></li>
<li><p><strong>retrieved_contexts</strong> – List of retrieved context chunks</p></li>
<li><p><strong>ground_truth_answer</strong> – The reference answer to compare against</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>EvaluationResult with score and explanation</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.RAGEvaluator.evaluate_faithfulness">
<span class="sig-name descname"><span class="pre">evaluate_faithfulness</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">question</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">generated_answer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retrieved_contexts</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#dllmforge.rag_evaluation.EvaluationResult" title="dllmforge.rag_evaluation.EvaluationResult"><span class="pre">EvaluationResult</span></a></span></span><a class="reference internal" href="_modules/dllmforge/rag_evaluation.html#RAGEvaluator.evaluate_faithfulness"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.RAGEvaluator.evaluate_faithfulness" title="Link to this definition">¶</a></dt>
<dd><p>Evaluate the faithfulness of the generated answer to the retrieved contexts.</p>
<p>This metric measures the factual accuracy of the generated answer by checking
if all statements in the answer are supported by the retrieved contexts.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>question</strong> – The user’s question</p></li>
<li><p><strong>generated_answer</strong> – The answer generated by the RAG system</p></li>
<li><p><strong>retrieved_contexts</strong> – List of retrieved context chunks</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>EvaluationResult with score and explanation</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.RAGEvaluator.evaluate_answer_relevancy">
<span class="sig-name descname"><span class="pre">evaluate_answer_relevancy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">question</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">generated_answer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#dllmforge.rag_evaluation.EvaluationResult" title="dllmforge.rag_evaluation.EvaluationResult"><span class="pre">EvaluationResult</span></a></span></span><a class="reference internal" href="_modules/dllmforge/rag_evaluation.html#RAGEvaluator.evaluate_answer_relevancy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.RAGEvaluator.evaluate_answer_relevancy" title="Link to this definition">¶</a></dt>
<dd><p>Evaluate the relevancy of the generated answer to the question.
This metric measures how relevant and to-the-point the answer is by generating
probable questions that the answer could answer and computing similarity to the actual question.
:param question: The user’s question
:param generated_answer: The answer generated by the RAG system</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>EvaluationResult with score and explanation</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.RAGEvaluator.calculate_ragas_score">
<span class="sig-name descname"><span class="pre">calculate_ragas_score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">context_precision</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context_recall</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">faithfulness</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">answer_relevancy</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="reference internal" href="_modules/dllmforge/rag_evaluation.html#RAGEvaluator.calculate_ragas_score"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.RAGEvaluator.calculate_ragas_score" title="Link to this definition">¶</a></dt>
<dd><p>Calculate the RAGAS score as the harmonic mean of all four metrics.
:param context_precision: Context precision score
:param context_recall: Context recall score
:param faithfulness: Faithfulness score
:param answer_relevancy: Answer relevancy score</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>RAGAS score (harmonic mean)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.RAGEvaluator.evaluate_rag_pipeline">
<span class="sig-name descname"><span class="pre">evaluate_rag_pipeline</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">question</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">generated_answer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retrieved_contexts</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ground_truth_answer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#dllmforge.rag_evaluation.RAGEvaluationResult" title="dllmforge.rag_evaluation.RAGEvaluationResult"><span class="pre">RAGEvaluationResult</span></a></span></span><a class="reference internal" href="_modules/dllmforge/rag_evaluation.html#RAGEvaluator.evaluate_rag_pipeline"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.RAGEvaluator.evaluate_rag_pipeline" title="Link to this definition">¶</a></dt>
<dd><p>Evaluate a complete RAG pipeline using all four metrics.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>question</strong> – The user’s question</p></li>
<li><p><strong>generated_answer</strong> – The answer generated by the RAG system</p></li>
<li><p><strong>retrieved_contexts</strong> – List of retrieved context chunks</p></li>
<li><p><strong>ground_truth_answer</strong> – Optional ground truth answer for context recall evaluation</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Complete evaluation results</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.RAGEvaluator.print_evaluation_summary">
<span class="sig-name descname"><span class="pre">print_evaluation_summary</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">result</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#dllmforge.rag_evaluation.RAGEvaluationResult" title="dllmforge.rag_evaluation.RAGEvaluationResult"><span class="pre">RAGEvaluationResult</span></a></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/rag_evaluation.html#RAGEvaluator.print_evaluation_summary"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.RAGEvaluator.print_evaluation_summary" title="Link to this definition">¶</a></dt>
<dd><p>Print a formatted summary of the evaluation results.
:param result: The evaluation results to summarize</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.RAGEvaluator.save_evaluation_results">
<span class="sig-name descname"><span class="pre">save_evaluation_results</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">result</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#dllmforge.rag_evaluation.RAGEvaluationResult" title="dllmforge.rag_evaluation.RAGEvaluationResult"><span class="pre">RAGEvaluationResult</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_file</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/rag_evaluation.html#RAGEvaluator.save_evaluation_results"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.RAGEvaluator.save_evaluation_results" title="Link to this definition">¶</a></dt>
<dd><p>Save evaluation results to a JSON file.
:param result: The evaluation results to save
:param output_file: Path to the output JSON file</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dllmforge.AnthropicAPI">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dllmforge.</span></span><span class="sig-name descname"><span class="pre">AnthropicAPI</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">api_key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'claude-3-7-sonnet-20250219'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deployment_claude37</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deployment_claude35</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/anthropic_api.html#AnthropicAPI"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.AnthropicAPI" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Class to interact with Anthropic’s Claude API.</p>
<p>Initialize the Anthropic API client with configuration.</p>
<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.AnthropicAPI.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">api_key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'claude-3-7-sonnet-20250219'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deployment_claude37</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deployment_claude35</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/anthropic_api.html#AnthropicAPI.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.AnthropicAPI.__init__" title="Link to this definition">¶</a></dt>
<dd><p>Initialize the Anthropic API client with configuration.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.AnthropicAPI.check_server_status">
<span class="sig-name descname"><span class="pre">check_server_status</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/anthropic_api.html#AnthropicAPI.check_server_status"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.AnthropicAPI.check_server_status" title="Link to this definition">¶</a></dt>
<dd><p>Check if the Anthropic API service is accessible.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.AnthropicAPI.list_available_models">
<span class="sig-name descname"><span class="pre">list_available_models</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/anthropic_api.html#AnthropicAPI.list_available_models"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.AnthropicAPI.list_available_models" title="Link to this definition">¶</a></dt>
<dd><p>List available models from Anthropic.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.AnthropicAPI.send_test_message">
<span class="sig-name descname"><span class="pre">send_test_message</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'Hello,</span> <span class="pre">how</span> <span class="pre">are</span> <span class="pre">you?'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/anthropic_api.html#AnthropicAPI.send_test_message"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.AnthropicAPI.send_test_message" title="Link to this definition">¶</a></dt>
<dd><p>Send a test message to the model and get a response.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.AnthropicAPI.chat_completion">
<span class="sig-name descname"><span class="pre">chat_completion</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.7</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_tokens</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/anthropic_api.html#AnthropicAPI.chat_completion"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.AnthropicAPI.chat_completion" title="Link to this definition">¶</a></dt>
<dd><p>Get a chat completion from the model.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dllmforge.LlamaIndexAPI">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dllmforge.</span></span><span class="sig-name descname"><span class="pre">LlamaIndexAPI</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_provider</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'azure-openai'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_base</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_version</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deployment_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/llamaindex_api.html#LlamaIndexAPI"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.LlamaIndexAPI" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Class to interact with various LLM providers using LlamaIndex.</p>
<p>Initialize the LlamaIndex API client with specified configuration.
:param model_provider: Provider of model to use. Options are:</p>
<blockquote>
<div><ul class="simple">
<li><p>“azure-openai”: Use Azure OpenAI</p></li>
<li><p>“openai”: Use OpenAI</p></li>
<li><p>“mistral”: Use Mistral</p></li>
</ul>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>temperature</strong> (<em>float</em>) – Temperature setting for the model (0.0 to 1.0)</p></li>
<li><p><strong>api_key</strong> (<em>str</em>) – API key for the provider</p></li>
<li><p><strong>api_base</strong> (<em>str</em>) – API base URL (for Azure)</p></li>
<li><p><strong>api_version</strong> (<em>str</em>) – API version (for Azure)</p></li>
<li><p><strong>deployment_name</strong> (<em>str</em>) – Deployment name (for Azure)</p></li>
<li><p><strong>model_name</strong> (<em>str</em>) – Model name (for OpenAI/Mistral)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.LlamaIndexAPI.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_provider</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'azure-openai'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_base</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_version</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deployment_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/llamaindex_api.html#LlamaIndexAPI.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.LlamaIndexAPI.__init__" title="Link to this definition">¶</a></dt>
<dd><p>Initialize the LlamaIndex API client with specified configuration.
:param model_provider: Provider of model to use. Options are:</p>
<blockquote>
<div><ul class="simple">
<li><p>“azure-openai”: Use Azure OpenAI</p></li>
<li><p>“openai”: Use OpenAI</p></li>
<li><p>“mistral”: Use Mistral</p></li>
</ul>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>temperature</strong> (<em>float</em>) – Temperature setting for the model (0.0 to 1.0)</p></li>
<li><p><strong>api_key</strong> (<em>str</em>) – API key for the provider</p></li>
<li><p><strong>api_base</strong> (<em>str</em>) – API base URL (for Azure)</p></li>
<li><p><strong>api_version</strong> (<em>str</em>) – API version (for Azure)</p></li>
<li><p><strong>deployment_name</strong> (<em>str</em>) – Deployment name (for Azure)</p></li>
<li><p><strong>model_name</strong> (<em>str</em>) – Model name (for OpenAI/Mistral)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.LlamaIndexAPI.check_server_status">
<span class="sig-name descname"><span class="pre">check_server_status</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/llamaindex_api.html#LlamaIndexAPI.check_server_status"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.LlamaIndexAPI.check_server_status" title="Link to this definition">¶</a></dt>
<dd><p>Check if the LLM service is accessible.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.LlamaIndexAPI.send_test_message">
<span class="sig-name descname"><span class="pre">send_test_message</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prompt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'Hello,</span> <span class="pre">how</span> <span class="pre">are</span> <span class="pre">you?'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/llamaindex_api.html#LlamaIndexAPI.send_test_message"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.LlamaIndexAPI.send_test_message" title="Link to this definition">¶</a></dt>
<dd><p>Send a test message to the model and get a response.
:param prompt: The prompt string to send.
:type prompt: str</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Dictionary containing the response and metadata.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.LlamaIndexAPI.chat_completion">
<span class="sig-name descname"><span class="pre">chat_completion</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">messages</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_tokens</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dllmforge/llamaindex_api.html#LlamaIndexAPI.chat_completion"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.LlamaIndexAPI.chat_completion" title="Link to this definition">¶</a></dt>
<dd><p>Get a chat completion from the model.
:param messages: List of message dicts or tuples (role, content)
:type messages: list
:param temperature: Optional temperature override
:type temperature: float
:param max_tokens: Optional max tokens override
:type max_tokens: int</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Dictionary containing the response and metadata.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>dict</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">dllmforge</a></h1>









<search id="searchbox" style="display: none" role="search">
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" placeholder="Search"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script><h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">Tutorials:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="tutorials/LLM_tutorial.html">Tutorial LLM capabilities of DLLMForge</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials/RAG_tutorial.html">Open Source RAG Pipeline Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials/tutorial_simple_agent.html">Building a Simple Agent with DLLMForge</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials/tutorial_advanced_agent.html">Tutorial: Advanced Water Management Agent</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials/Information_extraction_tutorial.html">Information Extraction with LLMs Tutorial</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Background:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="background/LLM_explained.html">LLM Explained</a></li>
<li class="toctree-l1"><a class="reference internal" href="background/RAGS_explained.html">Retrieval-Augmented Generation (RAG)</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="_autosummary/dllmforge.html">dllmforge</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;2023-2025, dllmforge team.
      
    </div>

    

    
  </body>
</html>