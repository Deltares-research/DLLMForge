<!DOCTYPE html>

<html lang="en" data-content_root="../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>dllmforge.rag_evaluation &#8212; dllmforge  documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=5ecbeea2" />
    <link rel="stylesheet" type="text/css" href="../_static/basic.css?v=686e5160" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css?v=27fed22d" />
    <script src="../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="dllmforge.rag_preprocess_documents" href="dllmforge.rag_preprocess_documents.html" />
    <link rel="prev" title="dllmforge.rag_embedding_open_source" href="dllmforge.rag_embedding_open_source.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="module-dllmforge.rag_evaluation">
<span id="dllmforge-rag-evaluation"></span><h1>dllmforge.rag_evaluation<a class="headerlink" href="#module-dllmforge.rag_evaluation" title="Link to this heading">¶</a></h1>
<p>RAGAS Evaluation Module for DLLMForge</p>
<p>This module provides comprehensive evaluation metrics for RAG (Retrieval-Augmented Generation)
pipelines using RAGAS-inspired metrics without requiring external dashboards or services.</p>
<p>The module evaluates four key aspects of RAG systems:
1. Context Precision -
2. Context Recall - measures the ability to retrieve all necessary information
3. Faithfulness - measures factual accuracy and absence of hallucinations
4. Answer Relevancy - measures how relevant and to-the-point answers are</p>
<p>All evaluations are performed using LLMs to provide human-like assessment without requiring
annotated datasets.</p>
<p class="rubric">Functions</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="../dllmforge.html#dllmforge.rag_evaluation.evaluate_rag_response" title="dllmforge.rag_evaluation.evaluate_rag_response"><code class="xref py py-obj docutils literal notranslate"><span class="pre">evaluate_rag_response</span></code></a>(question, ...[, ...])</p></td>
<td><p>Convenience function to evaluate a RAG response.</p></td>
</tr>
</tbody>
</table>
<p class="rubric">Classes</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="../dllmforge.html#dllmforge.rag_evaluation.EvaluationResult" title="dllmforge.rag_evaluation.EvaluationResult"><code class="xref py py-obj docutils literal notranslate"><span class="pre">EvaluationResult</span></code></a>(metric_name, score, ...)</p></td>
<td><p>Container for evaluation results.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="../dllmforge.html#dllmforge.rag_evaluation.RAGEvaluationResult" title="dllmforge.rag_evaluation.RAGEvaluationResult"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RAGEvaluationResult</span></code></a>(context_precision, ...)</p></td>
<td><p>Container for complete RAG evaluation results.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="../dllmforge.html#dllmforge.rag_evaluation.RAGEvaluator" title="dllmforge.rag_evaluation.RAGEvaluator"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RAGEvaluator</span></code></a>([llm_provider, deltares_llm, ...])</p></td>
<td><p>RAGAS-inspired evaluator for RAG pipelines.</p></td>
</tr>
</tbody>
</table>
<dl class="py class">
<dt class="sig sig-object py" id="dllmforge.rag_evaluation.EvaluationResult">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dllmforge.rag_evaluation.</span></span><span class="sig-name descname"><span class="pre">EvaluationResult</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">metric_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">score</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">explanation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">details</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/dllmforge/rag_evaluation.html#EvaluationResult"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_evaluation.EvaluationResult" title="Link to this definition">¶</a></dt>
<dd><p>Container for evaluation results.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="dllmforge.rag_evaluation.EvaluationResult.metric_name">
<span class="sig-name descname"><span class="pre">metric_name</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><a class="headerlink" href="#dllmforge.rag_evaluation.EvaluationResult.metric_name" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dllmforge.rag_evaluation.EvaluationResult.score">
<span class="sig-name descname"><span class="pre">score</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><a class="headerlink" href="#dllmforge.rag_evaluation.EvaluationResult.score" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dllmforge.rag_evaluation.EvaluationResult.explanation">
<span class="sig-name descname"><span class="pre">explanation</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><a class="headerlink" href="#dllmforge.rag_evaluation.EvaluationResult.explanation" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dllmforge.rag_evaluation.EvaluationResult.details">
<span class="sig-name descname"><span class="pre">details</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#dllmforge.rag_evaluation.EvaluationResult.details" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.rag_evaluation.EvaluationResult.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">metric_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">score</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">explanation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">details</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dllmforge.rag_evaluation.EvaluationResult.__init__" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dllmforge.rag_evaluation.RAGEvaluationResult">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dllmforge.rag_evaluation.</span></span><span class="sig-name descname"><span class="pre">RAGEvaluationResult</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">context_precision</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../dllmforge.html#dllmforge.rag_evaluation.EvaluationResult" title="dllmforge.rag_evaluation.EvaluationResult"><span class="pre">EvaluationResult</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">context_recall</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../dllmforge.html#dllmforge.rag_evaluation.EvaluationResult" title="dllmforge.rag_evaluation.EvaluationResult"><span class="pre">EvaluationResult</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">faithfulness</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../dllmforge.html#dllmforge.rag_evaluation.EvaluationResult" title="dllmforge.rag_evaluation.EvaluationResult"><span class="pre">EvaluationResult</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">answer_relevancy</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../dllmforge.html#dllmforge.rag_evaluation.EvaluationResult" title="dllmforge.rag_evaluation.EvaluationResult"><span class="pre">EvaluationResult</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">ragas_score</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">evaluation_time</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metadata</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/dllmforge/rag_evaluation.html#RAGEvaluationResult"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_evaluation.RAGEvaluationResult" title="Link to this definition">¶</a></dt>
<dd><p>Container for complete RAG evaluation results.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="dllmforge.rag_evaluation.RAGEvaluationResult.context_precision">
<span class="sig-name descname"><span class="pre">context_precision</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="../dllmforge.html#dllmforge.rag_evaluation.EvaluationResult" title="dllmforge.rag_evaluation.EvaluationResult"><span class="pre">EvaluationResult</span></a></em><a class="headerlink" href="#dllmforge.rag_evaluation.RAGEvaluationResult.context_precision" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dllmforge.rag_evaluation.RAGEvaluationResult.context_recall">
<span class="sig-name descname"><span class="pre">context_recall</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="../dllmforge.html#dllmforge.rag_evaluation.EvaluationResult" title="dllmforge.rag_evaluation.EvaluationResult"><span class="pre">EvaluationResult</span></a></em><a class="headerlink" href="#dllmforge.rag_evaluation.RAGEvaluationResult.context_recall" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dllmforge.rag_evaluation.RAGEvaluationResult.faithfulness">
<span class="sig-name descname"><span class="pre">faithfulness</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="../dllmforge.html#dllmforge.rag_evaluation.EvaluationResult" title="dllmforge.rag_evaluation.EvaluationResult"><span class="pre">EvaluationResult</span></a></em><a class="headerlink" href="#dllmforge.rag_evaluation.RAGEvaluationResult.faithfulness" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dllmforge.rag_evaluation.RAGEvaluationResult.answer_relevancy">
<span class="sig-name descname"><span class="pre">answer_relevancy</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="../dllmforge.html#dllmforge.rag_evaluation.EvaluationResult" title="dllmforge.rag_evaluation.EvaluationResult"><span class="pre">EvaluationResult</span></a></em><a class="headerlink" href="#dllmforge.rag_evaluation.RAGEvaluationResult.answer_relevancy" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dllmforge.rag_evaluation.RAGEvaluationResult.ragas_score">
<span class="sig-name descname"><span class="pre">ragas_score</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><a class="headerlink" href="#dllmforge.rag_evaluation.RAGEvaluationResult.ragas_score" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dllmforge.rag_evaluation.RAGEvaluationResult.evaluation_time">
<span class="sig-name descname"><span class="pre">evaluation_time</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><a class="headerlink" href="#dllmforge.rag_evaluation.RAGEvaluationResult.evaluation_time" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dllmforge.rag_evaluation.RAGEvaluationResult.metadata">
<span class="sig-name descname"><span class="pre">metadata</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#dllmforge.rag_evaluation.RAGEvaluationResult.metadata" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.rag_evaluation.RAGEvaluationResult.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">context_precision</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../dllmforge.html#dllmforge.rag_evaluation.EvaluationResult" title="dllmforge.rag_evaluation.EvaluationResult"><span class="pre">EvaluationResult</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">context_recall</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../dllmforge.html#dllmforge.rag_evaluation.EvaluationResult" title="dllmforge.rag_evaluation.EvaluationResult"><span class="pre">EvaluationResult</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">faithfulness</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../dllmforge.html#dllmforge.rag_evaluation.EvaluationResult" title="dllmforge.rag_evaluation.EvaluationResult"><span class="pre">EvaluationResult</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">answer_relevancy</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../dllmforge.html#dllmforge.rag_evaluation.EvaluationResult" title="dllmforge.rag_evaluation.EvaluationResult"><span class="pre">EvaluationResult</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">ragas_score</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">evaluation_time</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metadata</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dllmforge.rag_evaluation.RAGEvaluationResult.__init__" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dllmforge.rag_evaluation.RAGEvaluator">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dllmforge.rag_evaluation.</span></span><span class="sig-name descname"><span class="pre">RAGEvaluator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">llm_provider</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deltares_llm</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DeltaresOllamaLLM</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_base</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_version</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deployment_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/dllmforge/rag_evaluation.html#RAGEvaluator"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_evaluation.RAGEvaluator" title="Link to this definition">¶</a></dt>
<dd><p>RAGAS-inspired evaluator for RAG pipelines.</p>
<p>This evaluator provides four key metrics:
- Context Precision:
- Context Recall: Measures the ability to retrieve all necessary information
- Faithfulness: Measures factual accuracy and absence of hallucinations
- Answer Relevancy: Measures how relevant and to-the-point answers are</p>
<p>Initialize the RAG evaluator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>llm_provider</strong> – LLM provider to use (“openai”, “anthropic”, “deltares” or “auto”)</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.rag_evaluation.RAGEvaluator.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">llm_provider</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deltares_llm</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DeltaresOllamaLLM</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_key</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_base</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">api_version</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deployment_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/dllmforge/rag_evaluation.html#RAGEvaluator.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_evaluation.RAGEvaluator.__init__" title="Link to this definition">¶</a></dt>
<dd><p>Initialize the RAG evaluator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>llm_provider</strong> – LLM provider to use (“openai”, “anthropic”, “deltares” or “auto”)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.rag_evaluation.RAGEvaluator.evaluate_context_relevancy">
<span class="sig-name descname"><span class="pre">evaluate_context_relevancy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">question</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retrieved_contexts</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../dllmforge.html#dllmforge.rag_evaluation.EvaluationResult" title="dllmforge.rag_evaluation.EvaluationResult"><span class="pre">EvaluationResult</span></a></span></span><a class="reference internal" href="../_modules/dllmforge/rag_evaluation.html#RAGEvaluator.evaluate_context_relevancy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_evaluation.RAGEvaluator.evaluate_context_relevancy" title="Link to this definition">¶</a></dt>
<dd><p>Evaluate the relevancy of retrieved contexts to the question.</p>
<p>This metric measures the signal-to-noise ratio in the retrieved contexts.
It identifies which sentences from the context are actually needed to answer the question.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>question</strong> – The user’s question</p></li>
<li><p><strong>retrieved_contexts</strong> – List of retrieved context chunks</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>EvaluationResult with score and explanation</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.rag_evaluation.RAGEvaluator.evaluate_context_precision">
<span class="sig-name descname"><span class="pre">evaluate_context_precision</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">question</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retrieved_contexts</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ground_truth_answer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_k</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../dllmforge.html#dllmforge.rag_evaluation.EvaluationResult" title="dllmforge.rag_evaluation.EvaluationResult"><span class="pre">EvaluationResult</span></a></span></span><a class="reference internal" href="../_modules/dllmforge/rag_evaluation.html#RAGEvaluator.evaluate_context_precision"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_evaluation.RAGEvaluator.evaluate_context_precision" title="Link to this definition">¶</a></dt>
<dd><p>Evaluate Context Precision&#64;k following the Ragas implementation.</p>
<p>For each of the top-k retrieved chunks, the LLM judges whether the chunk
supports the reference answer. Average Precision (AP) is then computed as:</p>
<blockquote>
<div><p>AP = sum(Precision&#64;i * rel_i) / (# relevant chunks)</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>question</strong> – The question to evaluate.</p></li>
<li><p><strong>reference_answer</strong> – The correct or gold answer.</p></li>
<li><p><strong>retrieved_contexts</strong> – Ranked list of retrieved chunks.</p></li>
<li><p><strong>top_k</strong> – Number of top chunks to evaluate.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>EvaluationResult with precision&#64;k score and explanation.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.rag_evaluation.RAGEvaluator.evaluate_context_recall">
<span class="sig-name descname"><span class="pre">evaluate_context_recall</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">question</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retrieved_contexts</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ground_truth_answer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../dllmforge.html#dllmforge.rag_evaluation.EvaluationResult" title="dllmforge.rag_evaluation.EvaluationResult"><span class="pre">EvaluationResult</span></a></span></span><a class="reference internal" href="../_modules/dllmforge/rag_evaluation.html#RAGEvaluator.evaluate_context_recall"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_evaluation.RAGEvaluator.evaluate_context_recall" title="Link to this definition">¶</a></dt>
<dd><p>Evaluate the recall of retrieved contexts against a ground truth answer.
This metric measures the ability of the retriever to retrieve all necessary information
needed to answer the question by checking if each statement from the ground truth
can be found in the retrieved context.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>question</strong> – The user’s question</p></li>
<li><p><strong>retrieved_contexts</strong> – List of retrieved context chunks</p></li>
<li><p><strong>ground_truth_answer</strong> – The reference answer to compare against</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>EvaluationResult with score and explanation</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.rag_evaluation.RAGEvaluator.evaluate_faithfulness">
<span class="sig-name descname"><span class="pre">evaluate_faithfulness</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">question</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">generated_answer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retrieved_contexts</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../dllmforge.html#dllmforge.rag_evaluation.EvaluationResult" title="dllmforge.rag_evaluation.EvaluationResult"><span class="pre">EvaluationResult</span></a></span></span><a class="reference internal" href="../_modules/dllmforge/rag_evaluation.html#RAGEvaluator.evaluate_faithfulness"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_evaluation.RAGEvaluator.evaluate_faithfulness" title="Link to this definition">¶</a></dt>
<dd><p>Evaluate the faithfulness of the generated answer to the retrieved contexts.</p>
<p>This metric measures the factual accuracy of the generated answer by checking
if all statements in the answer are supported by the retrieved contexts.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>question</strong> – The user’s question</p></li>
<li><p><strong>generated_answer</strong> – The answer generated by the RAG system</p></li>
<li><p><strong>retrieved_contexts</strong> – List of retrieved context chunks</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>EvaluationResult with score and explanation</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.rag_evaluation.RAGEvaluator.evaluate_answer_relevancy">
<span class="sig-name descname"><span class="pre">evaluate_answer_relevancy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">question</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">generated_answer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../dllmforge.html#dllmforge.rag_evaluation.EvaluationResult" title="dllmforge.rag_evaluation.EvaluationResult"><span class="pre">EvaluationResult</span></a></span></span><a class="reference internal" href="../_modules/dllmforge/rag_evaluation.html#RAGEvaluator.evaluate_answer_relevancy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_evaluation.RAGEvaluator.evaluate_answer_relevancy" title="Link to this definition">¶</a></dt>
<dd><p>Evaluate the relevancy of the generated answer to the question.
This metric measures how relevant and to-the-point the answer is by generating
probable questions that the answer could answer and computing similarity to the actual question.
:param question: The user’s question
:param generated_answer: The answer generated by the RAG system</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>EvaluationResult with score and explanation</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.rag_evaluation.RAGEvaluator.calculate_ragas_score">
<span class="sig-name descname"><span class="pre">calculate_ragas_score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">context_precision</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context_recall</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">faithfulness</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">answer_relevancy</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="reference internal" href="../_modules/dllmforge/rag_evaluation.html#RAGEvaluator.calculate_ragas_score"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_evaluation.RAGEvaluator.calculate_ragas_score" title="Link to this definition">¶</a></dt>
<dd><p>Calculate the RAGAS score as the harmonic mean of all four metrics.
:param context_precision: Context precision score
:param context_recall: Context recall score
:param faithfulness: Faithfulness score
:param answer_relevancy: Answer relevancy score</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>RAGAS score (harmonic mean)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.rag_evaluation.RAGEvaluator.evaluate_rag_pipeline">
<span class="sig-name descname"><span class="pre">evaluate_rag_pipeline</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">question</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">generated_answer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retrieved_contexts</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ground_truth_answer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../dllmforge.html#dllmforge.rag_evaluation.RAGEvaluationResult" title="dllmforge.rag_evaluation.RAGEvaluationResult"><span class="pre">RAGEvaluationResult</span></a></span></span><a class="reference internal" href="../_modules/dllmforge/rag_evaluation.html#RAGEvaluator.evaluate_rag_pipeline"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_evaluation.RAGEvaluator.evaluate_rag_pipeline" title="Link to this definition">¶</a></dt>
<dd><p>Evaluate a complete RAG pipeline using all four metrics.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>question</strong> – The user’s question</p></li>
<li><p><strong>generated_answer</strong> – The answer generated by the RAG system</p></li>
<li><p><strong>retrieved_contexts</strong> – List of retrieved context chunks</p></li>
<li><p><strong>ground_truth_answer</strong> – Optional ground truth answer for context recall evaluation</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Complete evaluation results</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.rag_evaluation.RAGEvaluator.print_evaluation_summary">
<span class="sig-name descname"><span class="pre">print_evaluation_summary</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">result</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../dllmforge.html#dllmforge.rag_evaluation.RAGEvaluationResult" title="dllmforge.rag_evaluation.RAGEvaluationResult"><span class="pre">RAGEvaluationResult</span></a></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/dllmforge/rag_evaluation.html#RAGEvaluator.print_evaluation_summary"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_evaluation.RAGEvaluator.print_evaluation_summary" title="Link to this definition">¶</a></dt>
<dd><p>Print a formatted summary of the evaluation results.
:param result: The evaluation results to summarize</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dllmforge.rag_evaluation.RAGEvaluator.save_evaluation_results">
<span class="sig-name descname"><span class="pre">save_evaluation_results</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">result</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../dllmforge.html#dllmforge.rag_evaluation.RAGEvaluationResult" title="dllmforge.rag_evaluation.RAGEvaluationResult"><span class="pre">RAGEvaluationResult</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_file</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/dllmforge/rag_evaluation.html#RAGEvaluator.save_evaluation_results"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_evaluation.RAGEvaluator.save_evaluation_results" title="Link to this definition">¶</a></dt>
<dd><p>Save evaluation results to a JSON file.
:param result: The evaluation results to save
:param output_file: Path to the output JSON file</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dllmforge.rag_evaluation.evaluate_rag_response">
<span class="sig-prename descclassname"><span class="pre">dllmforge.rag_evaluation.</span></span><span class="sig-name descname"><span class="pre">evaluate_rag_response</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">question</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">generated_answer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retrieved_contexts</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ground_truth_answer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">llm_provider</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_results</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_file</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../dllmforge.html#dllmforge.rag_evaluation.RAGEvaluationResult" title="dllmforge.rag_evaluation.RAGEvaluationResult"><span class="pre">RAGEvaluationResult</span></a></span></span><a class="reference internal" href="../_modules/dllmforge/rag_evaluation.html#evaluate_rag_response"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dllmforge.rag_evaluation.evaluate_rag_response" title="Link to this definition">¶</a></dt>
<dd><p>Convenience function to evaluate a RAG response.
:param question: The user’s question
:param generated_answer: The answer generated by the RAG system
:param retrieved_contexts: List of retrieved context chunks
:param ground_truth_answer: Optional ground truth answer for context recall evaluation
:param llm_provider: LLM provider to use (“openai”, “anthropic”, or “auto”)
:param save_results: Whether to save results to a file
:param output_file: Optional output file path</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Complete evaluation results</p>
</dd>
</dl>
</dd></dl>

</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../index.html">dllmforge</a></h1>









<search id="searchbox" style="display: none" role="search">
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" placeholder="Search"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script><h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">Tutorials:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/LLM_tutorial.html">Tutorial LLM capabilities of DLLMForge</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/RAG_tutorial.html">Open Source RAG Pipeline Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/tutorial_simple_agent.html">Building a Simple Agent with DLLMForge</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/tutorial_advanced_agent.html">Tutorial: Advanced Water Management Agent</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/Information_extraction_tutorial.html">Information Extraction with LLMs Tutorial</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Background:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../background/LLM_explained.html">LLM Explained</a></li>
<li class="toctree-l1"><a class="reference internal" href="../background/RAGS_explained.html">Retrieval-Augmented Generation (RAG)</a></li>
</ul>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="dllmforge.html">dllmforge</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="dllmforge.html#dllmforge.SimpleAgent"><code class="docutils literal notranslate"><span class="pre">SimpleAgent</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="dllmforge.html#dllmforge.create_basic_agent"><code class="docutils literal notranslate"><span class="pre">create_basic_agent()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="dllmforge.html#dllmforge.create_basic_tools"><code class="docutils literal notranslate"><span class="pre">create_basic_tools()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="dllmforge.html#dllmforge.AzureOpenAIEmbeddingModel"><code class="docutils literal notranslate"><span class="pre">AzureOpenAIEmbeddingModel</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="dllmforge.html#dllmforge.PDFLoader"><code class="docutils literal notranslate"><span class="pre">PDFLoader</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="dllmforge.html#dllmforge.TextChunker"><code class="docutils literal notranslate"><span class="pre">TextChunker</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="dllmforge.html#dllmforge.IndexManager"><code class="docutils literal notranslate"><span class="pre">IndexManager</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="dllmforge.html#dllmforge.Retriever"><code class="docutils literal notranslate"><span class="pre">Retriever</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="dllmforge.html#dllmforge.LLMResponder"><code class="docutils literal notranslate"><span class="pre">LLMResponder</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="dllmforge.html#dllmforge.RAGEvaluator"><code class="docutils literal notranslate"><span class="pre">RAGEvaluator</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="dllmforge.html#dllmforge.AnthropicAPI"><code class="docutils literal notranslate"><span class="pre">AnthropicAPI</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="dllmforge.html#dllmforge.LlamaIndexAPI"><code class="docutils literal notranslate"><span class="pre">LlamaIndexAPI</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="dllmforge.IE_agent_config.html">dllmforge.IE_agent_config</a></li>
<li class="toctree-l2"><a class="reference internal" href="dllmforge.IE_agent_document_processor.html">dllmforge.IE_agent_document_processor</a></li>
<li class="toctree-l2"><a class="reference internal" href="dllmforge.IE_agent_extractor.html">dllmforge.IE_agent_extractor</a></li>
<li class="toctree-l2"><a class="reference internal" href="dllmforge.IE_agent_extractor_docling.html">dllmforge.IE_agent_extractor_docling</a></li>
<li class="toctree-l2"><a class="reference internal" href="dllmforge.IE_agent_schema_generator.html">dllmforge.IE_agent_schema_generator</a></li>
<li class="toctree-l2"><a class="reference internal" href="dllmforge.agent_core.html">dllmforge.agent_core</a></li>
<li class="toctree-l2"><a class="reference internal" href="dllmforge.anthropic_api.html">dllmforge.anthropic_api</a></li>
<li class="toctree-l2"><a class="reference internal" href="dllmforge.langchain_api.html">dllmforge.langchain_api</a></li>
<li class="toctree-l2"><a class="reference internal" href="dllmforge.llamaindex_api.html">dllmforge.llamaindex_api</a></li>
<li class="toctree-l2"><a class="reference internal" href="dllmforge.openai_api.html">dllmforge.openai_api</a></li>
<li class="toctree-l2"><a class="reference internal" href="dllmforge.rag_embedding.html">dllmforge.rag_embedding</a></li>
<li class="toctree-l2"><a class="reference internal" href="dllmforge.rag_embedding_open_source.html">dllmforge.rag_embedding_open_source</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">dllmforge.rag_evaluation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#dllmforge.rag_evaluation.EvaluationResult"><code class="docutils literal notranslate"><span class="pre">EvaluationResult</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#dllmforge.rag_evaluation.EvaluationResult.metric_name"><code class="docutils literal notranslate"><span class="pre">EvaluationResult.metric_name</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dllmforge.rag_evaluation.EvaluationResult.score"><code class="docutils literal notranslate"><span class="pre">EvaluationResult.score</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dllmforge.rag_evaluation.EvaluationResult.explanation"><code class="docutils literal notranslate"><span class="pre">EvaluationResult.explanation</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dllmforge.rag_evaluation.EvaluationResult.details"><code class="docutils literal notranslate"><span class="pre">EvaluationResult.details</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dllmforge.rag_evaluation.EvaluationResult.__init__"><code class="docutils literal notranslate"><span class="pre">EvaluationResult.__init__()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#dllmforge.rag_evaluation.RAGEvaluationResult"><code class="docutils literal notranslate"><span class="pre">RAGEvaluationResult</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#dllmforge.rag_evaluation.RAGEvaluationResult.context_precision"><code class="docutils literal notranslate"><span class="pre">RAGEvaluationResult.context_precision</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dllmforge.rag_evaluation.RAGEvaluationResult.context_recall"><code class="docutils literal notranslate"><span class="pre">RAGEvaluationResult.context_recall</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dllmforge.rag_evaluation.RAGEvaluationResult.faithfulness"><code class="docutils literal notranslate"><span class="pre">RAGEvaluationResult.faithfulness</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dllmforge.rag_evaluation.RAGEvaluationResult.answer_relevancy"><code class="docutils literal notranslate"><span class="pre">RAGEvaluationResult.answer_relevancy</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dllmforge.rag_evaluation.RAGEvaluationResult.ragas_score"><code class="docutils literal notranslate"><span class="pre">RAGEvaluationResult.ragas_score</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dllmforge.rag_evaluation.RAGEvaluationResult.evaluation_time"><code class="docutils literal notranslate"><span class="pre">RAGEvaluationResult.evaluation_time</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dllmforge.rag_evaluation.RAGEvaluationResult.metadata"><code class="docutils literal notranslate"><span class="pre">RAGEvaluationResult.metadata</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dllmforge.rag_evaluation.RAGEvaluationResult.__init__"><code class="docutils literal notranslate"><span class="pre">RAGEvaluationResult.__init__()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#dllmforge.rag_evaluation.RAGEvaluator"><code class="docutils literal notranslate"><span class="pre">RAGEvaluator</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#dllmforge.rag_evaluation.RAGEvaluator.__init__"><code class="docutils literal notranslate"><span class="pre">RAGEvaluator.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dllmforge.rag_evaluation.RAGEvaluator.evaluate_context_relevancy"><code class="docutils literal notranslate"><span class="pre">RAGEvaluator.evaluate_context_relevancy()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dllmforge.rag_evaluation.RAGEvaluator.evaluate_context_precision"><code class="docutils literal notranslate"><span class="pre">RAGEvaluator.evaluate_context_precision()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dllmforge.rag_evaluation.RAGEvaluator.evaluate_context_recall"><code class="docutils literal notranslate"><span class="pre">RAGEvaluator.evaluate_context_recall()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dllmforge.rag_evaluation.RAGEvaluator.evaluate_faithfulness"><code class="docutils literal notranslate"><span class="pre">RAGEvaluator.evaluate_faithfulness()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dllmforge.rag_evaluation.RAGEvaluator.evaluate_answer_relevancy"><code class="docutils literal notranslate"><span class="pre">RAGEvaluator.evaluate_answer_relevancy()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dllmforge.rag_evaluation.RAGEvaluator.calculate_ragas_score"><code class="docutils literal notranslate"><span class="pre">RAGEvaluator.calculate_ragas_score()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dllmforge.rag_evaluation.RAGEvaluator.evaluate_rag_pipeline"><code class="docutils literal notranslate"><span class="pre">RAGEvaluator.evaluate_rag_pipeline()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dllmforge.rag_evaluation.RAGEvaluator.print_evaluation_summary"><code class="docutils literal notranslate"><span class="pre">RAGEvaluator.print_evaluation_summary()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dllmforge.rag_evaluation.RAGEvaluator.save_evaluation_results"><code class="docutils literal notranslate"><span class="pre">RAGEvaluator.save_evaluation_results()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#dllmforge.rag_evaluation.evaluate_rag_response"><code class="docutils literal notranslate"><span class="pre">evaluate_rag_response()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="dllmforge.rag_preprocess_documents.html">dllmforge.rag_preprocess_documents</a></li>
<li class="toctree-l2"><a class="reference internal" href="dllmforge.rag_search_and_response.html">dllmforge.rag_search_and_response</a></li>
</ul>
</li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
  <li><a href="dllmforge.html">dllmforge</a><ul>
      <li>Previous: <a href="dllmforge.rag_embedding_open_source.html" title="previous chapter">dllmforge.rag_embedding_open_source</a></li>
      <li>Next: <a href="dllmforge.rag_preprocess_documents.html" title="next chapter">dllmforge.rag_preprocess_documents</a></li>
  </ul></li>
  </ul></li>
</ul>
</div>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;2023-2025, dllmforge team.
      
    </div>

    

    
  </body>
</html>